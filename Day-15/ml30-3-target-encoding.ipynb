{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Statistics\nimport pandas as pd\nimport numpy as np\nimport math as mt\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Data Preprocessing - Standardization, Encoding, Imputation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\n\n\n# Data Preprocessing - Feature Engineering\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.decomposition import PCA\n\n# Data Preprocessing - ML Pipelines\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n# ML - Modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\n# ML - Evaluation\nfrom sklearn.model_selection import cross_val_score\n\n# ML - Tuning\nfrom sklearn.model_selection import GridSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T23:54:50.875509Z","iopub.execute_input":"2021-08-24T23:54:50.875905Z","iopub.status.idle":"2021-08-24T23:54:52.242517Z","shell.execute_reply.started":"2021-08-24T23:54:50.875808Z","shell.execute_reply":"2021-08-24T23:54:52.241580Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Read train dataset\ntrain_data = pd.read_csv('../input/30days-folds/train_folds.csv')\ntest_data = pd.read_csv('../input/30-days-of-ml/test.csv')\nsample_submission = pd.read_csv('../input/30-days-of-ml/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:19:19.777765Z","iopub.execute_input":"2021-08-25T00:19:19.778142Z","iopub.status.idle":"2021-08-25T00:19:21.949181Z","shell.execute_reply.started":"2021-08-25T00:19:19.778108Z","shell.execute_reply":"2021-08-25T00:19:21.948205Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"%%time\n# target encoding\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor col in cat_cols:\n    temp_df = []\n    temp_test_feat = None\n    for fold in range(5):\n        X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n        X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n        feat = X_train.groupby(col)[\"target\"].agg(\"mean\")\n        feat = feat.to_dict()\n        #print(feat)\n        X_valid.loc[:, f\"tar_enc_{col}\"] = X_valid[col].map(feat)\n        temp_df.append(X_valid)\n        if temp_test_feat is None:\n            temp_test_feat = test_data[col].map(feat)\n        else:\n            temp_test_feat += test_data[col].map(feat)\n    temp_test_feat /= 5\n    test_data.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n    train_data = pd.concat(temp_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:19:21.950896Z","iopub.execute_input":"2021-08-25T00:19:21.951307Z","iopub.status.idle":"2021-08-25T00:19:28.956576Z","shell.execute_reply.started":"2021-08-25T00:19:21.951265Z","shell.execute_reply":"2021-08-25T00:19:28.954982Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"CPU times: user 6.54 s, sys: 454 ms, total: 7 s\nWall time: 7 s\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:19:28.958314Z","iopub.execute_input":"2021-08-25T00:19:28.958699Z","iopub.status.idle":"2021-08-25T00:19:28.990561Z","shell.execute_reply.started":"2021-08-25T00:19:28.958659Z","shell.execute_reply":"2021-08-25T00:19:28.989381Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ... tar_enc_cat0  \\\n0   1    B    B    B    C    B    B    A    E    C  ...     8.245979   \n1   8    B    A    A    A    B    D    A    E    C  ...     8.245979   \n2  13    A    B    A    C    B    B    A    E    A  ...     8.238970   \n3  14    B    B    A    C    B    D    A    E    C  ...     8.245979   \n4  25    B    B    A    C    B    D    A    E    C  ...     8.245979   \n\n   tar_enc_cat1  tar_enc_cat2  tar_enc_cat3  tar_enc_cat4  tar_enc_cat5  \\\n0      8.203850      8.224780      8.236717      8.240572      8.229516   \n1      8.276689      8.244491      8.274495      8.240572      8.250754   \n2      8.203850      8.244491      8.236717      8.240572      8.229516   \n3      8.203850      8.244491      8.236717      8.240572      8.250754   \n4      8.203850      8.244491      8.236717      8.240572      8.250754   \n\n   tar_enc_cat6  tar_enc_cat7  tar_enc_cat8  tar_enc_cat9  \n0      8.240567      8.240285      8.280709      8.249782  \n1      8.240567      8.240285      8.280709      8.259165  \n2      8.240567      8.240285      8.230681      8.249782  \n3      8.240567      8.240285      8.280709      8.234356  \n4      8.240567      8.240285      8.280709      8.259165  \n\n[5 rows x 37 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>tar_enc_cat0</th>\n      <th>tar_enc_cat1</th>\n      <th>tar_enc_cat2</th>\n      <th>tar_enc_cat3</th>\n      <th>tar_enc_cat4</th>\n      <th>tar_enc_cat5</th>\n      <th>tar_enc_cat6</th>\n      <th>tar_enc_cat7</th>\n      <th>tar_enc_cat8</th>\n      <th>tar_enc_cat9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>8.245979</td>\n      <td>8.203850</td>\n      <td>8.224780</td>\n      <td>8.236717</td>\n      <td>8.240572</td>\n      <td>8.229516</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.280709</td>\n      <td>8.249782</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>8.245979</td>\n      <td>8.276689</td>\n      <td>8.244491</td>\n      <td>8.274495</td>\n      <td>8.240572</td>\n      <td>8.250754</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.280709</td>\n      <td>8.259165</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>8.238970</td>\n      <td>8.203850</td>\n      <td>8.244491</td>\n      <td>8.236717</td>\n      <td>8.240572</td>\n      <td>8.229516</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.230681</td>\n      <td>8.249782</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>8.245979</td>\n      <td>8.203850</td>\n      <td>8.244491</td>\n      <td>8.236717</td>\n      <td>8.240572</td>\n      <td>8.250754</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.280709</td>\n      <td>8.234356</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>8.245979</td>\n      <td>8.203850</td>\n      <td>8.244491</td>\n      <td>8.236717</td>\n      <td>8.240572</td>\n      <td>8.250754</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.280709</td>\n      <td>8.259165</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 37 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if col.startswith(\"cat\")]\ntest_data = test_data[useful_features]","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:19:48.561905Z","iopub.execute_input":"2021-08-25T00:19:48.562302Z","iopub.status.idle":"2021-08-25T00:19:48.624566Z","shell.execute_reply.started":"2021-08-25T00:19:48.562267Z","shell.execute_reply":"2021-08-25T00:19:48.623653Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"%%time\n# Target Encoding\nfor fold in range(5):\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    #print(\"encoding\")\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    #print(\"training\")\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model.fit(X_train, y_train)\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:20:03.311428Z","iopub.execute_input":"2021-08-25T00:20:03.311783Z","iopub.status.idle":"2021-08-25T00:20:29.932391Z","shell.execute_reply.started":"2021-08-25T00:20:03.311740Z","shell.execute_reply":"2021-08-25T00:20:29.930139Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0 0.7242269269359577\n1 0.7240495957228682\n2 0.7255552929019189\n3 0.7307805951556532\n4 0.7923764903298341\n0.7393977802092464 0.026602013514808294\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:21:57.381830Z","iopub.execute_input":"2021-08-25T00:21:57.382242Z","iopub.status.idle":"2021-08-25T00:21:57.443724Z","shell.execute_reply.started":"2021-08-25T00:21:57.382210Z","shell.execute_reply":"2021-08-25T00:21:57.442509Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"        cat0  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  ...  \\\n0        1.0   1.0   1.0   2.0   1.0   1.0   0.0   4.0   2.0  13.0  ...   \n1        1.0   0.0   0.0   0.0   1.0   3.0   0.0   4.0   2.0   5.0  ...   \n2        0.0   1.0   0.0   2.0   1.0   1.0   0.0   4.0   0.0  13.0  ...   \n3        1.0   1.0   0.0   2.0   1.0   3.0   0.0   4.0   2.0   6.0  ...   \n4        1.0   1.0   0.0   2.0   1.0   3.0   0.0   4.0   2.0   5.0  ...   \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n239995   0.0   0.0   0.0   2.0   1.0   3.0   1.0   4.0   6.0   5.0  ...   \n239996   0.0   1.0   0.0   2.0   1.0   3.0   0.0   4.0   0.0   5.0  ...   \n239997   1.0   0.0   0.0   2.0   1.0   1.0   0.0   4.0   4.0   8.0  ...   \n239998   0.0   1.0   0.0   2.0   1.0   1.0   0.0   4.0   4.0   5.0  ...   \n239999   0.0   1.0   0.0   2.0   1.0   1.0   0.0   4.0   4.0   8.0  ...   \n\n        tar_enc_cat0  tar_enc_cat1  tar_enc_cat2  tar_enc_cat3  tar_enc_cat4  \\\n0           8.245979      8.203850      8.224780      8.236717      8.240572   \n1           8.245979      8.276689      8.244491      8.274495      8.240572   \n2           8.238970      8.203850      8.244491      8.236717      8.240572   \n3           8.245979      8.203850      8.244491      8.236717      8.240572   \n4           8.245979      8.203850      8.244491      8.236717      8.240572   \n...              ...           ...           ...           ...           ...   \n239995      8.239318      8.278803      8.245484      8.237347      8.241200   \n239996      8.239318      8.203374      8.245484      8.237347      8.241200   \n239997      8.247711      8.278803      8.245484      8.237347      8.241200   \n239998      8.239318      8.203374      8.245484      8.237347      8.241200   \n239999      8.239318      8.203374      8.245484      8.237347      8.241200   \n\n        tar_enc_cat5  tar_enc_cat6  tar_enc_cat7  tar_enc_cat8  tar_enc_cat9  \n0           8.229516      8.240567      8.240285      8.280709      8.249782  \n1           8.250754      8.240567      8.240285      8.280709      8.259165  \n2           8.229516      8.240567      8.240285      8.230681      8.249782  \n3           8.250754      8.240567      8.240285      8.280709      8.234356  \n4           8.250754      8.240567      8.240285      8.280709      8.259165  \n...              ...           ...           ...           ...           ...  \n239995      8.251611      8.264177      8.240682      8.257484      8.259797  \n239996      8.251611      8.241397      8.240682      8.230168      8.259797  \n239997      8.230389      8.241397      8.240682      8.192147      8.223627  \n239998      8.230389      8.241397      8.240682      8.192147      8.259797  \n239999      8.230389      8.241397      8.240682      8.192147      8.223627  \n\n[240000 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>cat9</th>\n      <th>...</th>\n      <th>tar_enc_cat0</th>\n      <th>tar_enc_cat1</th>\n      <th>tar_enc_cat2</th>\n      <th>tar_enc_cat3</th>\n      <th>tar_enc_cat4</th>\n      <th>tar_enc_cat5</th>\n      <th>tar_enc_cat6</th>\n      <th>tar_enc_cat7</th>\n      <th>tar_enc_cat8</th>\n      <th>tar_enc_cat9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>...</td>\n      <td>8.245979</td>\n      <td>8.203850</td>\n      <td>8.224780</td>\n      <td>8.236717</td>\n      <td>8.240572</td>\n      <td>8.229516</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.280709</td>\n      <td>8.249782</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>8.245979</td>\n      <td>8.276689</td>\n      <td>8.244491</td>\n      <td>8.274495</td>\n      <td>8.240572</td>\n      <td>8.250754</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.280709</td>\n      <td>8.259165</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>...</td>\n      <td>8.238970</td>\n      <td>8.203850</td>\n      <td>8.244491</td>\n      <td>8.236717</td>\n      <td>8.240572</td>\n      <td>8.229516</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.230681</td>\n      <td>8.249782</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>8.245979</td>\n      <td>8.203850</td>\n      <td>8.244491</td>\n      <td>8.236717</td>\n      <td>8.240572</td>\n      <td>8.250754</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.280709</td>\n      <td>8.234356</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>8.245979</td>\n      <td>8.203850</td>\n      <td>8.244491</td>\n      <td>8.236717</td>\n      <td>8.240572</td>\n      <td>8.250754</td>\n      <td>8.240567</td>\n      <td>8.240285</td>\n      <td>8.280709</td>\n      <td>8.259165</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>239995</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>8.239318</td>\n      <td>8.278803</td>\n      <td>8.245484</td>\n      <td>8.237347</td>\n      <td>8.241200</td>\n      <td>8.251611</td>\n      <td>8.264177</td>\n      <td>8.240682</td>\n      <td>8.257484</td>\n      <td>8.259797</td>\n    </tr>\n    <tr>\n      <th>239996</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>8.239318</td>\n      <td>8.203374</td>\n      <td>8.245484</td>\n      <td>8.237347</td>\n      <td>8.241200</td>\n      <td>8.251611</td>\n      <td>8.241397</td>\n      <td>8.240682</td>\n      <td>8.230168</td>\n      <td>8.259797</td>\n    </tr>\n    <tr>\n      <th>239997</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>8.247711</td>\n      <td>8.278803</td>\n      <td>8.245484</td>\n      <td>8.237347</td>\n      <td>8.241200</td>\n      <td>8.230389</td>\n      <td>8.241397</td>\n      <td>8.240682</td>\n      <td>8.192147</td>\n      <td>8.223627</td>\n    </tr>\n    <tr>\n      <th>239998</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>8.239318</td>\n      <td>8.203374</td>\n      <td>8.245484</td>\n      <td>8.237347</td>\n      <td>8.241200</td>\n      <td>8.230389</td>\n      <td>8.241397</td>\n      <td>8.240682</td>\n      <td>8.192147</td>\n      <td>8.259797</td>\n    </tr>\n    <tr>\n      <th>239999</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>8.239318</td>\n      <td>8.203374</td>\n      <td>8.245484</td>\n      <td>8.237347</td>\n      <td>8.241200</td>\n      <td>8.230389</td>\n      <td>8.241397</td>\n      <td>8.240682</td>\n      <td>8.192147</td>\n      <td>8.223627</td>\n    </tr>\n  </tbody>\n</table>\n<p>240000 rows Ã— 34 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# With Standardization + Normalization\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n\n    # Preprocessing - Standardization\n    scaler = StandardScaler()\n    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Preprocessing - Normalizatino\n    normalizer = Normalizer()\n    X_train[num_cols] = normalizer.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = normalizer.transform(X_valid[num_cols])\n    X_test[num_cols] = normalizer.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:44:15.294985Z","iopub.execute_input":"2021-08-24T21:44:15.295451Z","iopub.status.idle":"2021-08-24T21:44:38.737812Z","shell.execute_reply.started":"2021-08-24T21:44:15.295406Z","shell.execute_reply":"2021-08-24T21:44:38.736862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# With Standardization\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Preprocessing - Standardization\n    scaler = StandardScaler()\n    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Log transformation + Tuning\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfor col in num_cols:\n    train_data[col] = np.log1p(train_data[col])\n    test_data[col] = np.log1p(test_data[col])\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:47:08.741473Z","iopub.execute_input":"2021-08-24T21:47:08.741828Z","iopub.status.idle":"2021-08-24T21:47:37.645747Z","shell.execute_reply.started":"2021-08-24T21:47:08.741796Z","shell.execute_reply":"2021-08-24T21:47:37.644785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# polynomial features + Tuning\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\npoly = PolynomialFeatures(degree=2, \n                          interaction_only=True, # If true, only interaction features are produced: features that are products of at most degree distinct input features (so not x[1] ** 2, x[0] * x[2] ** 3, etc.).\n                          include_bias=False)\ntrain_poly = poly.fit_transform(train_data[num_cols])\ntest_poly = poly.fit_transform(test_data[num_cols])\n\ndf_train_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\ndf_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n\ntrain_data = pd.concat([train_data, df_train_poly], axis=1)\ntest_data = pd.concat([test_data, df_test_poly], axis=1)\n\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:20:02.277023Z","iopub.execute_input":"2021-08-24T22:20:02.27741Z","iopub.status.idle":"2021-08-24T22:20:55.762472Z","shell.execute_reply.started":"2021-08-24T22:20:02.277378Z","shell.execute_reply":"2021-08-24T22:20:55.761626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:29:42.845424Z","iopub.execute_input":"2021-08-24T22:29:42.845783Z","iopub.status.idle":"2021-08-24T22:29:42.932702Z","shell.execute_reply.started":"2021-08-24T22:29:42.845746Z","shell.execute_reply":"2021-08-24T22:29:42.931612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# One-Hot Encoding + Ordinal Encoding + Tuning\n# pd.cut \n# Model Tuning + drop cat2\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\noe_cols = ['cat9']\nohe_cols = cat_cols\nohe_cols.remove('cat9')\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[oe_cols] = ordinal_encoder.fit_transform(X_train[oe_cols])\n    X_valid[oe_cols] = ordinal_encoder.transform(X_valid[oe_cols])\n    X_test[oe_cols] = ordinal_encoder.transform(X_test[oe_cols]) # Q. The last transform\n    \n    # Preprocessing - One-Hot Encoding\n    ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n    X_train_ohe = ohe.fit_transform(X_train[ohe_cols])\n    X_valid_ohe = ohe.transform(X_valid[ohe_cols])\n    X_test_ohe = ohe.transform(X_test[ohe_cols]) # Q. The last transform\n    \n    X_train_ohe = pd.DataFrame(X_train_ohe, columns=[f\"ohe_{i}\" for i in range(X_train_ohe.shape[1])])\n    X_valid_ohe = pd.DataFrame(X_valid_ohe, columns=[f\"ohe_{i}\" for i in range(X_valid_ohe.shape[1])])\n    X_test_ohe = pd.DataFrame(X_test_ohe, columns=[f\"ohe_{i}\" for i in range(X_test_ohe.shape[1])])\n    \n    X_train = pd.concat([X_train.drop(columns=ohe_cols), X_train_ohe], axis=1)\n    X_valid = pd.concat([X_valid.drop(columns=ohe_cols), X_valid_ohe], axis=1)\n    X_test = pd.concat([X_test.drop(columns=ohe_cols), X_test_ohe], axis=1)\n\n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:42:37.746539Z","iopub.execute_input":"2021-08-24T22:42:37.746908Z","iopub.status.idle":"2021-08-24T22:43:05.859597Z","shell.execute_reply.started":"2021-08-24T22:42:37.746864Z","shell.execute_reply":"2021-08-24T22:43:05.857667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Model Tuning + drop cat2\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\", \"cat2\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:54:06.321382Z","iopub.execute_input":"2021-08-24T21:54:06.321743Z","iopub.status.idle":"2021-08-24T21:54:33.276709Z","shell.execute_reply.started":"2021-08-24T21:54:06.321709Z","shell.execute_reply":"2021-08-24T21:54:33.275794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Model Tuning + drop cat2, cat6\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\", \"cat2\", \"cat6\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:55:30.031254Z","iopub.execute_input":"2021-08-24T21:55:30.031587Z","iopub.status.idle":"2021-08-24T21:55:54.609825Z","shell.execute_reply.started":"2021-08-24T21:55:30.031558Z","shell.execute_reply":"2021-08-24T21:55:54.608783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Tuning + Standardization\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Preprocessing - Standardization\n    scaler = StandardScaler()\n    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:31:05.89861Z","iopub.execute_input":"2021-08-24T22:31:05.898981Z","iopub.status.idle":"2021-08-24T22:31:33.912625Z","shell.execute_reply.started":"2021-08-24T22:31:05.898945Z","shell.execute_reply":"2021-08-24T22:31:33.911724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Only Model Tuning\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:50:43.55151Z","iopub.execute_input":"2021-08-24T21:50:43.551835Z","iopub.status.idle":"2021-08-24T21:51:12.086803Z","shell.execute_reply.started":"2021-08-24T21:50:43.551803Z","shell.execute_reply":"2021-08-24T21:51:12.085859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Export submission.csv\npreds = np.mean(np.column_stack(final_predictions), axis=1)\npreds = pd.DataFrame({'id': sample_submission.id, 'target': preds})\npreds.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:48:43.959974Z","iopub.execute_input":"2021-08-24T21:48:43.960328Z","iopub.status.idle":"2021-08-24T21:48:44.474981Z","shell.execute_reply.started":"2021-08-24T21:48:43.960296Z","shell.execute_reply":"2021-08-24T21:48:44.474102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}