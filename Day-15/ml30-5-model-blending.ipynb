{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Preprocessing - Standardization, Encoding, Imputation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# Data Preprocessing - Feature Engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Data Preprocessing - ML Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ML - Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ML - Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ML - Tuning\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T19:58:35.563049Z",
     "iopub.status.busy": "2021-08-25T19:58:35.562727Z",
     "iopub.status.idle": "2021-08-25T20:00:38.923128Z",
     "shell.execute_reply": "2021-08-25T20:00:38.922219Z",
     "shell.execute_reply.started": "2021-08-25T19:58:35.563018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.50031\n",
      "[1000]\tvalidation_0-rmse:0.72395\n",
      "[2000]\tvalidation_0-rmse:0.72000\n",
      "[3000]\tvalidation_0-rmse:0.71849\n",
      "[4000]\tvalidation_0-rmse:0.71770\n",
      "[5000]\tvalidation_0-rmse:0.71730\n",
      "[6000]\tvalidation_0-rmse:0.71705\n",
      "[7000]\tvalidation_0-rmse:0.71693\n",
      "[8000]\tvalidation_0-rmse:0.71688\n",
      "[8522]\tvalidation_0-rmse:0.71687\n",
      "0 0.7168573307459428\n",
      "[0]\tvalidation_0-rmse:7.49707\n",
      "[1000]\tvalidation_0-rmse:0.72356\n",
      "[2000]\tvalidation_0-rmse:0.71967\n",
      "[3000]\tvalidation_0-rmse:0.71825\n",
      "[4000]\tvalidation_0-rmse:0.71751\n",
      "[5000]\tvalidation_0-rmse:0.71714\n",
      "[6000]\tvalidation_0-rmse:0.71696\n",
      "[7000]\tvalidation_0-rmse:0.71688\n",
      "[8000]\tvalidation_0-rmse:0.71682\n",
      "[8063]\tvalidation_0-rmse:0.71681\n",
      "1 0.7168120224667079\n",
      "[0]\tvalidation_0-rmse:7.49474\n",
      "[1000]\tvalidation_0-rmse:0.72527\n",
      "[2000]\tvalidation_0-rmse:0.72145\n",
      "[3000]\tvalidation_0-rmse:0.71996\n",
      "[4000]\tvalidation_0-rmse:0.71932\n",
      "[5000]\tvalidation_0-rmse:0.71894\n",
      "[6000]\tvalidation_0-rmse:0.71872\n",
      "[7000]\tvalidation_0-rmse:0.71863\n",
      "[7931]\tvalidation_0-rmse:0.71862\n",
      "2 0.7185994471569308\n",
      "[0]\tvalidation_0-rmse:7.49705\n",
      "[1000]\tvalidation_0-rmse:0.72544\n",
      "[2000]\tvalidation_0-rmse:0.72153\n",
      "[3000]\tvalidation_0-rmse:0.72008\n",
      "[4000]\tvalidation_0-rmse:0.71939\n",
      "[5000]\tvalidation_0-rmse:0.71899\n",
      "[6000]\tvalidation_0-rmse:0.71882\n",
      "[7000]\tvalidation_0-rmse:0.71871\n",
      "[8000]\tvalidation_0-rmse:0.71864\n",
      "[9000]\tvalidation_0-rmse:0.71862\n",
      "[9187]\tvalidation_0-rmse:0.71862\n",
      "3 0.7186056377572814\n",
      "[0]\tvalidation_0-rmse:7.50250\n",
      "[1000]\tvalidation_0-rmse:0.72479\n",
      "[2000]\tvalidation_0-rmse:0.72049\n",
      "[3000]\tvalidation_0-rmse:0.71881\n",
      "[4000]\tvalidation_0-rmse:0.71799\n",
      "[5000]\tvalidation_0-rmse:0.71753\n",
      "[6000]\tvalidation_0-rmse:0.71734\n",
      "[7000]\tvalidation_0-rmse:0.71724\n",
      "[7615]\tvalidation_0-rmse:0.71721\n",
      "4 0.7172010858995527\n",
      "0.7176151048052831 0.0008173933956283648\n",
      "CPU times: user 2min 2s, sys: 1.36 s, total: 2min 3s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "class Model_Blending:\n",
    "    def __init__(self):\n",
    "        import warnings\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        # Import datasets\n",
    "        self.df_train = pd.read_csv('train_folds.csv')\n",
    "        #self.df_test = pd.read_csv('../input/30-days-of-ml/test.csv')\n",
    "        self.df_test = pd.read_csv('data/test.csv')\n",
    "        self.sample_submission = pd.read_csv('../input/30-days-of-ml/sample_submission.csv')\n",
    "        \n",
    "        # Define features\n",
    "        self.num_cols = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\n",
    "        self.onehot_cols = ['cat0', 'cat1', 'cat3', 'cat5', 'cat6', 'cat7', 'cat8'] # remove 'cat2', 'cat4' due to the low MI scores\n",
    "        self.ordinal_cols = ['cat9']\n",
    "        self.cat_cols = self.onehot_cols + self.ordinal_cols\n",
    "        self.useful_features = self.num_cols + self.cat_cols\n",
    "        self.target = 'target'\n",
    "    \n",
    "    # Preprocessing solution 0\n",
    "    def _ordinal_encoding(self, X_train, X_valid, X_test, params=True):\n",
    "        # Preprocessing - Ordinal Encoding\n",
    "        oe = OrdinalEncoder()\n",
    "        X_train[self.cat_cols] = oe.fit_transform(X_train[self.cat_cols])\n",
    "        X_valid[self.cat_cols] = oe.transform(X_valid[self.cat_cols])\n",
    "        X_test[self.cat_cols] = oe.transform(X_test[self.cat_cols])\n",
    "\n",
    "        # 200\n",
    "        # 0.7172987346930846\n",
    "        # XGBoost params\n",
    "        xgb_params = {\n",
    "            'alpha': 7.128681031027614,\n",
    "            'lambda': 0.40760576474680843,\n",
    "            'gamma': 0.08704298132127238,\n",
    "            'reg_alpha': 25.377502919374336,\n",
    "            'reg_lambda': 0.003401041649454036,\n",
    "            'colsample_bytree': 0.1355660282707954,\n",
    "            'subsample': 0.6999406375783235,\n",
    "            'learning_rate': 0.02338550339980208,\n",
    "            'n_estimators': 9263,\n",
    "            'max_depth': 6,\n",
    "            'random_state': 2021,\n",
    "            'min_child_weight': 138\n",
    "        }\n",
    "\n",
    "        # 200\n",
    "        # 0.7174088504920006\n",
    "        # LightGBM params\n",
    "        lgb_params = {\n",
    "            'random_state': 0, \n",
    "            'num_iterations': 9530, \n",
    "            'learning_rate': 0.018509357813869098, \n",
    "            'max_depth': 6, \n",
    "            'num_leaves': 98, \n",
    "            'min_data_in_leaf': 1772, \n",
    "            'lambda_l1': 0.0010866230909549698, \n",
    "            'lambda_l2': 1.6105154171511057e-05, \n",
    "            'feature_fraction': 0.09911317646202211, \n",
    "            'bagging_fraction': 0.8840672050147438, \n",
    "            'bagging_freq': 6, \n",
    "            'min_child_samples': 35\n",
    "        }\n",
    "        \n",
    "        if params == True:\n",
    "            return X_train, X_valid, X_test, xgb_params, lgb_params\n",
    "        else:\n",
    "            return X_train, X_valid, X_test\n",
    "    \n",
    "    # Preprocessing solution 1\n",
    "    def _onehot_encoding(self, X_train, X_valid, X_test):\n",
    "        # Preprocessing - One-hot Encoding\n",
    "        ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "        X_train_ohe = ohe.fit_transform(X_train[self.onehot_cols])\n",
    "        X_valid_ohe = ohe.transform(X_valid[self.onehot_cols])\n",
    "        X_test_ohe = ohe.transform(X_test[self.onehot_cols])\n",
    "\n",
    "        X_train_ohe = pd.DataFrame(X_train_ohe, columns=[f\"ohe_{i}\" for i in range(X_train_ohe.shape[1])])\n",
    "        X_valid_ohe = pd.DataFrame(X_valid_ohe, columns=[f\"ohe_{i}\" for i in range(X_valid_ohe.shape[1])])\n",
    "        X_test_ohe = pd.DataFrame(X_test_ohe, columns=[f\"ohe_{i}\" for i in range(X_test_ohe.shape[1])])\n",
    "\n",
    "        X_train = pd.concat([X_train.drop(columns=self.onehot_cols), X_train_ohe], axis=1)\n",
    "        X_valid = pd.concat([X_valid.drop(columns=self.onehot_cols), X_valid_ohe], axis=1)\n",
    "        X_test = pd.concat([X_test.drop(columns=self.onehot_cols), X_test_ohe], axis=1)\n",
    "        \n",
    "        # Preprocessing - Ordinal Encoding\n",
    "        oe = OrdinalEncoder()\n",
    "        X_train[self.ordinal_cols] = oe.fit_transform(X_train[self.ordinal_cols])\n",
    "        X_valid[self.ordinal_cols] = oe.transform(X_valid[self.ordinal_cols])\n",
    "        X_test[self.ordinal_cols] = oe.transform(X_test[self.ordinal_cols])\n",
    "    \n",
    "        # 200\n",
    "        # 0.7174931253475558\n",
    "        # XGBoost params\n",
    "        xgb_params = {\n",
    "            'alpha': 3.046687193123841,\n",
    "            'lambda': 0.7302844649944737,\n",
    "            'gamma': 0.10108768743909796,\n",
    "            'reg_alpha': 14.711350393993625,\n",
    "            'reg_lambda': 1.6855306764481926e-07,\n",
    "            'colsample_bytree': 0.15006790036326567,\n",
    "            'subsample': 0.9761751211889541,\n",
    "            'learning_rate': 0.02730958701307226,\n",
    "            'n_estimators': 7897,\n",
    "            'max_depth': 4,\n",
    "            'random_state': 0,\n",
    "            'min_child_weight': 203\n",
    "        }\n",
    "        \n",
    "        # 200\n",
    "        # 0.7172624587909345\n",
    "        # LightGBM params\n",
    "        lgb_params = {\n",
    "            'random_state': 42, \n",
    "            'num_iterations': 6969, \n",
    "            'learning_rate': 0.014404708757048168, \n",
    "            'max_depth': 7, \n",
    "            'num_leaves': 21, \n",
    "            'min_data_in_leaf': 1121, \n",
    "            'lambda_l1': 4.1636932334315094e-07, \n",
    "            'lambda_l2': 1.0975422991510602e-08, \n",
    "            'feature_fraction': 0.08082581387850206, \n",
    "            'bagging_fraction': 0.6804475225598854, \n",
    "            'bagging_freq': 2, \n",
    "            'min_child_samples': 32\n",
    "        }\n",
    "        \n",
    "        return X_train, X_valid, X_test, xgb_params, lgb_params\n",
    "\n",
    "    # Preprocessing solution 2\n",
    "    def _standardization(self, X_train, X_valid, X_test):\n",
    "        # Preprocessing - Standardization\n",
    "        scaler = StandardScaler()\n",
    "        X_train[self.num_cols] = scaler.fit_transform(X_train[self.num_cols])\n",
    "        X_valid[self.num_cols] = scaler.transform(X_valid[self.num_cols])\n",
    "        X_test[self.num_cols] = scaler.transform(X_test[self.num_cols])\n",
    "    \n",
    "        # 200\n",
    "        # 0.7172152365762312\n",
    "        # XGBoost params\n",
    "        xgb_params = {\n",
    "            'alpha': 0.029925179326119784,\n",
    "            'lambda': 0.12530061860157662,\n",
    "            'gamma': 0.5415753114227984,\n",
    "            'reg_alpha': 14.992919845445886,\n",
    "            'reg_lambda': 0.42076728548917974,\n",
    "            'colsample_bytree': 0.10022710624560974,\n",
    "            'subsample': 0.5596856445758918,\n",
    "            'learning_rate': 0.020866717779139694,\n",
    "            'n_estimators': 6852,\n",
    "            'max_depth': 7,\n",
    "            'random_state': 2021,\n",
    "            'min_child_weight': 62\n",
    "        }\n",
    "        \n",
    "        # 200\n",
    "        # 0.7173410652198884\n",
    "        # LightGBM params\n",
    "        lgb_params = {\n",
    "            'random_state': 0,\n",
    "            'num_iterations': 6439,\n",
    "            'learning_rate': 0.03625416364918611,\n",
    "            'max_depth': 6,\n",
    "            'num_leaves': 11,\n",
    "            'min_data_in_leaf': 745,\n",
    "            'lambda_l1': 4.1932281223524115e-06,\n",
    "            'lambda_l2': 0.043343249414638636,\n",
    "            'feature_fraction': 0.08623933710228435,\n",
    "            'bagging_fraction': 0.7934935001504152,\n",
    "            'bagging_freq': 3,\n",
    "            'min_child_samples': 23\n",
    "        }\n",
    "        \n",
    "        return X_train, X_valid, X_test, xgb_params, lgb_params\n",
    "\n",
    "    # Preprocessing solution 3\n",
    "    def _log_transformation(self, X_train, X_valid, X_test):\n",
    "        # Preprocessing - Log transformation\n",
    "        for col in self.num_cols:\n",
    "            X_train[col] = np.log1p(X_train[col])\n",
    "            X_valid[col] = np.log1p(X_valid[col])\n",
    "            X_test[col] = np.log1p(X_test[col])\n",
    "\n",
    "        # 200\n",
    "        # 0.7172539872780895\n",
    "        # XGBoost params\n",
    "        xgb_params = {\n",
    "            'alpha': 0.08862033338686888, \n",
    "            'lambda': 0.003553846716302233, \n",
    "            'gamma': 0.4097695581309838, \n",
    "            'reg_alpha': 17.808150656220917, \n",
    "            'reg_lambda': 1.6112661145526217, \n",
    "            'colsample_bytree': 0.11935885763757494, \n",
    "            'subsample': 0.7326515814471944, \n",
    "            'learning_rate': 0.04006687786137418, \n",
    "            'n_estimators': 5239, \n",
    "            'max_depth': 5, \n",
    "            'random_state': 2021, \n",
    "            'min_child_weight': 258\n",
    "        }\n",
    "\n",
    "        # 200\n",
    "        # 0.7174737448879298\n",
    "        # LightGBM params\n",
    "        lgb_params = {\n",
    "            'random_state': 0,\n",
    "            'num_iterations': 7945,\n",
    "            'learning_rate': 0.05205269244224801,\n",
    "            'max_depth': 6,\n",
    "            'num_leaves': 9,\n",
    "            'min_data_in_leaf': 1070,\n",
    "            'lambda_l1': 1.0744924634974802e-07,\n",
    "            'lambda_l2': 1.1250360028635182,\n",
    "            'feature_fraction': 0.10421484055936374,\n",
    "            'bagging_fraction': 0.916143112009066,\n",
    "            'bagging_freq': 6,\n",
    "            'min_child_samples': 20\n",
    "        }\n",
    "        \n",
    "        return X_train, X_valid, X_test, xgb_params, lgb_params\n",
    "\n",
    "    # Preprocessing solution 4\n",
    "    def _target_encoding(self, X_train, X_valid, X_test, y_train):\n",
    "        # Preprocessing - Target Encoding\n",
    "        te = MEstimateEncoder(cols=self.cat_cols, m=8) # m is from previous step\n",
    "        X_train = te.fit_transform(X_train, y_train)\n",
    "        X_valid = te.transform(X_valid)\n",
    "        X_test = te.transform(X_test)\n",
    "    \n",
    "        # 300\n",
    "        # 0.7172617296722674\n",
    "        # XGBoost params\n",
    "        xgb_params = {\n",
    "            'alpha': 0.012609024116174448,\n",
    "            'lambda': 0.7990281671135536,\n",
    "            'gamma': 0.16689280834519887,\n",
    "            'reg_alpha': 16.48576968441873,\n",
    "            'reg_lambda': 4.83082534682402e-08,\n",
    "            'colsample_bytree': 0.1162304168345657,\n",
    "            'subsample': 0.9126362948665406,\n",
    "            'learning_rate': 0.05528416190414117,\n",
    "            'n_estimators': 9670,\n",
    "            'max_depth': 5,\n",
    "            'random_state': 42,\n",
    "            'min_child_weight': 280\n",
    "         }\n",
    "\n",
    "        # 200\n",
    "        # 0.7173917173794985\n",
    "        # LightGBM params\n",
    "        lgb_params = {\n",
    "            'random_state': 2021, \n",
    "            'num_iterations': 7977, \n",
    "            'learning_rate': 0.01618931564625682, \n",
    "            'max_depth': 5, \n",
    "            'num_leaves': 50, \n",
    "            'min_data_in_leaf': 890, \n",
    "            'lambda_l1': 0.003233614433753064, \n",
    "            'lambda_l2': 2.0001872037801434e-06, \n",
    "            'feature_fraction': 0.13638848986185334, \n",
    "            'bagging_fraction': 0.7045068716734475, \n",
    "            'bagging_freq': 2, \n",
    "            'min_child_samples': 79\n",
    "        }\n",
    "        \n",
    "        return X_train, X_valid, X_test, xgb_params, lgb_params\n",
    "    \n",
    "    def _xgboost_reg(self, xgb_params):\n",
    "        model = XGBRegressor(\n",
    "                    tree_method='gpu_hist',\n",
    "                    gpu_id=0,\n",
    "                    predictor='gpu_predictor',\n",
    "                    n_jobs=-1,\n",
    "                    **xgb_params\n",
    "                )\n",
    "        return model\n",
    "    \n",
    "    def _lightgbm_reg(self, lgb_params):\n",
    "        model = LGBMRegressor(\n",
    "                    device='gpu',\n",
    "                    gpu_platform_id=0,\n",
    "                    gpu_device_id=0,\n",
    "                    n_jobs=-1,\n",
    "                    metric='rmse',\n",
    "                    **lgb_params\n",
    "                )\n",
    "        return model\n",
    "    \n",
    "    def blending(self, model: str):\n",
    "        '''Model blending. Generate 5 predictions according to 5 data preprocessing solutions.\n",
    "        \n",
    "        Args:\n",
    "            model: One of xgboost or lightgbm\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        assert model in ['xgboost', 'lightgbm'], \"ValueError: model must be one of ['xgboost', 'lightgbm']!\"\n",
    "        \n",
    "        # Loop preprocessing solutions\n",
    "        for preprocessing_solution in range(5):\n",
    "            final_valid_predictions = {} # store final predictions of X_valid for each preprocessing_solution\n",
    "            final_test_predictions = [] # store final predictions of X_test for each preprocessing_solution\n",
    "            scores = [] # store RMSE scores for each preprocessing_solution\n",
    "            print(f\"Data Preprocessing Solution: {preprocessing_solution}, Model: {model}\")\n",
    "            print(f\"Training ...\")\n",
    "            # Loop KFolds\n",
    "            for fold in range(5):\n",
    "                # Data Preprocessing\n",
    "                X_train = self.df_train[self.df_train.kfold != fold].reset_index(drop=True)\n",
    "                X_valid = self.df_train[self.df_train.kfold == fold].reset_index(drop=True)\n",
    "                X_test = self.df_test.copy()\n",
    "                \n",
    "                # get X_valid id\n",
    "                X_valid_ids = X_valid.id.values.tolist()\n",
    "                \n",
    "                y_train = X_train.pop(self.target)\n",
    "                X_train = X_train[self.useful_features] # not include id, cat2, cat4\n",
    "                y_valid = X_valid.pop(self.target)\n",
    "                X_valid = X_valid[self.useful_features] # not include id, cat2, cat4\n",
    "                X_test = X_test[self.useful_features]\n",
    "                \n",
    "                # Ordinal Encoding\n",
    "                if preprocessing_solution == 0:\n",
    "                    X_train, X_valid, X_test, xgb_params, lgb_params = self._ordinal_encoding(X_train, X_valid, X_test)\n",
    "                # One-hot Encoding + Ordinal Encoding\n",
    "                elif preprocessing_solution == 1:\n",
    "                    X_train, X_valid, X_test, xgb_params, lgb_params = self._onehot_encoding(X_train, X_valid, X_test)\n",
    "                # Ordinal Encoding + Standardization\n",
    "                elif preprocessing_solution == 2:\n",
    "                    X_train, X_valid, X_test = self._ordinal_encoding(X_train, X_valid, X_test, params=False)\n",
    "                    X_train, X_valid, X_test, xgb_params, lgb_params = self._standardization(X_train, X_valid, X_test)\n",
    "                # Ordinal Encoding + Log Transformation\n",
    "                elif preprocessing_solution == 3:\n",
    "                    X_train, X_valid, X_test = self._ordinal_encoding(X_train, X_valid, X_test, params=False)\n",
    "                    X_train, X_valid, X_test, xgb_params, lgb_params = self._log_transformation(X_train, X_valid, X_test)\n",
    "                # Target Encoding\n",
    "                elif preprocessing_solution == 4:\n",
    "                    X_train, X_valid, X_test, xgb_params, lgb_params = self._target_encoding(X_train, X_valid, X_test, y_train)\n",
    "                \n",
    "                # Define model\n",
    "                if model == 'xgboost':\n",
    "                    reg = self._xgboost_reg(xgb_params)\n",
    "                elif model == 'lightgbm':\n",
    "                    reg = self._lightgbm_reg(lgb_params)\n",
    "                \n",
    "                # Modeling - Training\n",
    "                reg.fit(\n",
    "                    X_train, y_train, \n",
    "                    early_stopping_rounds=300,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                # Modeling - Inference\n",
    "                valid_preds = reg.predict(X_valid)\n",
    "                test_preds = reg.predict(X_test)\n",
    "                \n",
    "                final_valid_predictions.update(dict(zip(X_valid_ids, valid_preds))) # loop 5 times with different valid id\n",
    "                final_test_predictions.append(test_preds) # loop 5 times and get the mean predictions for each row later\n",
    "\n",
    "                rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "                scores.append(rmse)\n",
    "                print(f'Data Preprocessing Solution: {preprocessing_solution}, Fold: {fold}, RMSE: {rmse}')\n",
    "                \n",
    "            # Export results\n",
    "            final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "            final_valid_predictions.columns = [\"id\", f\"{model}_{preprocessing_solution}_pred\"]\n",
    "            final_valid_predictions.to_csv(f\"{model}_{preprocessing_solution}_valid_pred.csv\", index=False)\n",
    "\n",
    "            test_mean_preds = np.mean(np.column_stack(final_test_predictions), axis=1) # get the meam predictions for each row\n",
    "            test_mean_preds = pd.DataFrame({'id': self.sample_submission.id, f\"{model}_{preprocessing_solution}_pred\": test_mean_preds})\n",
    "            test_mean_preds.to_csv(f\"{model}_{preprocessing_solution}_test_pred.csv\", index=False)\n",
    "            print(f'Average RMSE: {np.mean(scores)}, STD of RMSE: {np.std(scores)}')\n",
    "            print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:00:38.925182Z",
     "iopub.status.busy": "2021-08-25T20:00:38.924685Z",
     "iopub.status.idle": "2021-08-25T20:06:29.281949Z",
     "shell.execute_reply": "2021-08-25T20:06:29.281068Z",
     "shell.execute_reply.started": "2021-08-25T20:00:38.925143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.50030\n",
      "[1000]\tvalidation_0-rmse:0.72375\n",
      "[2000]\tvalidation_0-rmse:0.72144\n",
      "[3000]\tvalidation_0-rmse:0.72094\n",
      "[4000]\tvalidation_0-rmse:0.72078\n",
      "[4261]\tvalidation_0-rmse:0.72083\n",
      "0 0.720767827951469\n",
      "[0]\tvalidation_0-rmse:7.49705\n",
      "[1000]\tvalidation_0-rmse:0.72352\n",
      "[2000]\tvalidation_0-rmse:0.72124\n",
      "[3000]\tvalidation_0-rmse:0.72064\n",
      "[4000]\tvalidation_0-rmse:0.72047\n",
      "[4219]\tvalidation_0-rmse:0.72045\n",
      "1 0.7204373982348939\n",
      "[0]\tvalidation_0-rmse:7.49473\n",
      "[1000]\tvalidation_0-rmse:0.72539\n",
      "[2000]\tvalidation_0-rmse:0.72322\n",
      "[3000]\tvalidation_0-rmse:0.72267\n",
      "[3851]\tvalidation_0-rmse:0.72263\n",
      "2 0.7225806933088028\n",
      "[0]\tvalidation_0-rmse:7.49707\n",
      "[1000]\tvalidation_0-rmse:0.72515\n",
      "[2000]\tvalidation_0-rmse:0.72277\n",
      "[3000]\tvalidation_0-rmse:0.72218\n",
      "[3625]\tvalidation_0-rmse:0.72220\n",
      "3 0.72214507339082\n",
      "[0]\tvalidation_0-rmse:7.50251\n",
      "[1000]\tvalidation_0-rmse:0.72449\n",
      "[2000]\tvalidation_0-rmse:0.72208\n",
      "[3000]\tvalidation_0-rmse:0.72151\n",
      "[3571]\tvalidation_0-rmse:0.72143\n",
      "4 0.7214106603740207\n",
      "0.7214683306520013 0.0008064964919760797\n",
      "CPU times: user 5min 45s, sys: 15.3 s, total: 6min\n",
      "Wall time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Model 2 polynominal features\n",
    "train_data = pd.read_csv('../input/30days-folds/train_folds.csv')\n",
    "test_data = pd.read_csv('../input/30-days-of-ml/test.csv')\n",
    "\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, \n",
    "                          interaction_only=True, # If true, only interaction features are produced: features that are products of at most degree distinct input features (so not x[1] ** 2, x[0] * x[2] ** 3, etc.).\n",
    "                          include_bias=False)\n",
    "train_poly = poly.fit_transform(train_data[num_cols])\n",
    "test_poly = poly.fit_transform(test_data[num_cols])\n",
    "\n",
    "df_train_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\n",
    "df_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n",
    "\n",
    "train_data = pd.concat([train_data, df_train_poly], axis=1)\n",
    "test_data = pd.concat([test_data, df_test_poly], axis=1)\n",
    "\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_valid_predictions = {}\n",
    "final_test_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    X_valid_ids = X_valid.id.values.tolist()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    params = {\n",
    "        'random_state': 1, \n",
    "        'booster': 'gbtree',\n",
    "        'n_estimators': 10000,\n",
    "        'learning_rate': 0.03628302216953097,\n",
    "        'reg_lambda': 0.0008746338866473539,\n",
    "        'reg_alpha': 23.13181079976304,\n",
    "        'subsample': 0.7875490025178415,\n",
    "        'colsample_bytree': 0.11807135201147481,\n",
    "        'max_depth': 3\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(\n",
    "        tree_method='gpu_hist', \n",
    "        gpu_id=0, \n",
    "        predictor='gpu_predictor',\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train, early_stopping_rounds=300, eval_set=[(X_valid, y_valid)], verbose=1000)\n",
    "    \n",
    "    # Evaluation and Inference\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    \n",
    "    final_valid_predictions.update(dict(zip(X_valid_ids, preds_valid)))\n",
    "    final_test_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"id\", \"pred_2\"]\n",
    "final_valid_predictions.to_csv(\"train_pred_2.csv\", index=False)\n",
    "\n",
    "preds = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "preds = pd.DataFrame({'id': sample_submission.id, 'pred_2': preds})\n",
    "preds.to_csv(\"test_pred_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:06:29.284305Z",
     "iopub.status.busy": "2021-08-25T20:06:29.283816Z",
     "iopub.status.idle": "2021-08-25T20:08:42.539299Z",
     "shell.execute_reply": "2021-08-25T20:08:42.538463Z",
     "shell.execute_reply.started": "2021-08-25T20:06:29.284265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.50029\n",
      "[1000]\tvalidation_0-rmse:0.72337\n",
      "[2000]\tvalidation_0-rmse:0.71989\n",
      "[3000]\tvalidation_0-rmse:0.71849\n",
      "[4000]\tvalidation_0-rmse:0.71785\n",
      "[5000]\tvalidation_0-rmse:0.71751\n",
      "[6000]\tvalidation_0-rmse:0.71737\n",
      "[7000]\tvalidation_0-rmse:0.71730\n",
      "[7745]\tvalidation_0-rmse:0.71730\n",
      "0 0.7172629713248143\n",
      "[0]\tvalidation_0-rmse:7.49700\n",
      "[1000]\tvalidation_0-rmse:0.72288\n",
      "[2000]\tvalidation_0-rmse:0.71932\n",
      "[3000]\tvalidation_0-rmse:0.71804\n",
      "[4000]\tvalidation_0-rmse:0.71753\n",
      "[5000]\tvalidation_0-rmse:0.71726\n",
      "[6000]\tvalidation_0-rmse:0.71708\n",
      "[7000]\tvalidation_0-rmse:0.71695\n",
      "[7404]\tvalidation_0-rmse:0.71696\n",
      "1 0.7169390974696654\n",
      "[0]\tvalidation_0-rmse:7.49478\n",
      "[1000]\tvalidation_0-rmse:0.72462\n",
      "[2000]\tvalidation_0-rmse:0.72122\n",
      "[3000]\tvalidation_0-rmse:0.71988\n",
      "[4000]\tvalidation_0-rmse:0.71934\n",
      "[5000]\tvalidation_0-rmse:0.71904\n",
      "[6000]\tvalidation_0-rmse:0.71898\n",
      "[6760]\tvalidation_0-rmse:0.71897\n",
      "2 0.7189471800619452\n",
      "[0]\tvalidation_0-rmse:7.49701\n",
      "[1000]\tvalidation_0-rmse:0.72454\n",
      "[2000]\tvalidation_0-rmse:0.72114\n",
      "[3000]\tvalidation_0-rmse:0.71985\n",
      "[4000]\tvalidation_0-rmse:0.71932\n",
      "[5000]\tvalidation_0-rmse:0.71907\n",
      "[6000]\tvalidation_0-rmse:0.71893\n",
      "[7000]\tvalidation_0-rmse:0.71886\n",
      "[8000]\tvalidation_0-rmse:0.71883\n",
      "[8188]\tvalidation_0-rmse:0.71884\n",
      "3 0.7188212602389504\n",
      "[0]\tvalidation_0-rmse:7.50245\n",
      "[1000]\tvalidation_0-rmse:0.72475\n",
      "[2000]\tvalidation_0-rmse:0.72099\n",
      "[3000]\tvalidation_0-rmse:0.71957\n",
      "[4000]\tvalidation_0-rmse:0.71905\n",
      "[5000]\tvalidation_0-rmse:0.71880\n",
      "[5629]\tvalidation_0-rmse:0.71876\n",
      "4 0.7187469985550542\n",
      "0.718143501530086 0.000859696143100782\n",
      "CPU times: user 2min 12s, sys: 1.9 s, total: 2min 14s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Model 3 targeting encoding\n",
    "train_data = pd.read_csv('../input/30days-folds/train_folds.csv')\n",
    "test_data = pd.read_csv('../input/30-days-of-ml/test.csv')\n",
    "\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "for col in cat_cols:\n",
    "    temp_df = []\n",
    "    temp_test_feat = None\n",
    "    for fold in range(5):\n",
    "        X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "        feat = X_train.groupby(col)[\"target\"].agg(\"mean\")\n",
    "        feat = feat.to_dict()\n",
    "        #print(feat)\n",
    "        X_valid.loc[:, f\"tar_enc_{col}\"] = X_valid[col].map(feat)\n",
    "        temp_df.append(X_valid)\n",
    "        if temp_test_feat is None:\n",
    "            temp_test_feat = test_data[col].map(feat)\n",
    "        else:\n",
    "            temp_test_feat += test_data[col].map(feat)\n",
    "\n",
    "    temp_test_feat /= 5\n",
    "    test_data.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
    "    train_data = pd.concat(temp_df)\n",
    "    \n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if col.startswith(\"cat\")]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "\n",
    "final_valid_predictions = {}\n",
    "final_test_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    X_valid_ids = X_valid.id.values.tolist()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    params = {\n",
    "        'random_state': 1, \n",
    "        'booster': 'gbtree',\n",
    "        'n_estimators': 10000,\n",
    "        'learning_rate': 0.03628302216953097,\n",
    "        'reg_lambda': 0.0008746338866473539,\n",
    "        'reg_alpha': 23.13181079976304,\n",
    "        'subsample': 0.7875490025178415,\n",
    "        'colsample_bytree': 0.11807135201147481,\n",
    "        'max_depth': 3\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(\n",
    "        tree_method='gpu_hist', \n",
    "        gpu_id=0, \n",
    "        predictor='gpu_predictor',\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train, early_stopping_rounds=300, eval_set=[(X_valid, y_valid)], verbose=1000)\n",
    "    \n",
    "    # Evaluation and Inference\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    \n",
    "    final_valid_predictions.update(dict(zip(X_valid_ids, preds_valid)))\n",
    "    final_test_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"id\", \"pred_3\"]\n",
    "final_valid_predictions.to_csv(\"train_pred_3.csv\", index=False)\n",
    "\n",
    "preds = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "preds = pd.DataFrame({'id': sample_submission.id, 'pred_3': preds})\n",
    "preds.to_csv(\"test_pred_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:08:42.541271Z",
     "iopub.status.busy": "2021-08-25T20:08:42.540934Z",
     "iopub.status.idle": "2021-08-25T20:08:44.932556Z",
     "shell.execute_reply": "2021-08-25T20:08:44.931680Z",
     "shell.execute_reply.started": "2021-08-25T20:08:42.541236Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/30days-folds/train_folds.csv')\n",
    "test_data = pd.read_csv('../input/30-days-of-ml/test.csv')\n",
    "\n",
    "df_train1 = pd.read_csv('train_pred_1.csv')\n",
    "df_train2 = pd.read_csv('train_pred_2.csv')\n",
    "df_train3 = pd.read_csv('train_pred_3.csv')\n",
    "\n",
    "df_test1 = pd.read_csv('test_pred_1.csv')\n",
    "df_test2 = pd.read_csv('test_pred_2.csv')\n",
    "df_test3 = pd.read_csv('test_pred_3.csv')\n",
    "\n",
    "train_data = train_data.merge(df_train1, on=\"id\", how=\"left\")\n",
    "train_data = train_data.merge(df_train2, on=\"id\", how=\"left\")\n",
    "train_data = train_data.merge(df_train3, on=\"id\", how=\"left\")\n",
    "\n",
    "test_data = test_data.merge(df_test1, on=\"id\", how=\"left\")\n",
    "test_data = test_data.merge(df_test2, on=\"id\", how=\"left\")\n",
    "test_data = test_data.merge(df_test3, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:08:44.934219Z",
     "iopub.status.busy": "2021-08-25T20:08:44.933867Z",
     "iopub.status.idle": "2021-08-25T20:08:45.073625Z",
     "shell.execute_reply": "2021-08-25T20:08:45.072637Z",
     "shell.execute_reply.started": "2021-08-25T20:08:44.934185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>target</th>\n",
       "      <th>kfold</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.869850</td>\n",
       "      <td>8.113634</td>\n",
       "      <td>0</td>\n",
       "      <td>8.445581</td>\n",
       "      <td>8.404875</td>\n",
       "      <td>8.448442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>8.481233</td>\n",
       "      <td>2</td>\n",
       "      <td>8.374415</td>\n",
       "      <td>8.277811</td>\n",
       "      <td>8.316208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.763846</td>\n",
       "      <td>8.364351</td>\n",
       "      <td>4</td>\n",
       "      <td>8.195627</td>\n",
       "      <td>8.111172</td>\n",
       "      <td>8.139681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.714610</td>\n",
       "      <td>0.540150</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>8.049253</td>\n",
       "      <td>3</td>\n",
       "      <td>8.388680</td>\n",
       "      <td>8.305612</td>\n",
       "      <td>8.374855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>1.000773</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>0.625849</td>\n",
       "      <td>0.250823</td>\n",
       "      <td>7.972260</td>\n",
       "      <td>1</td>\n",
       "      <td>8.258226</td>\n",
       "      <td>8.220263</td>\n",
       "      <td>8.256620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>499993</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853726</td>\n",
       "      <td>0.422541</td>\n",
       "      <td>1.063463</td>\n",
       "      <td>0.697685</td>\n",
       "      <td>0.506404</td>\n",
       "      <td>7.945605</td>\n",
       "      <td>4</td>\n",
       "      <td>8.312504</td>\n",
       "      <td>8.330939</td>\n",
       "      <td>8.255457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>499996</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433525</td>\n",
       "      <td>0.301015</td>\n",
       "      <td>0.268447</td>\n",
       "      <td>0.577055</td>\n",
       "      <td>0.823611</td>\n",
       "      <td>7.326118</td>\n",
       "      <td>3</td>\n",
       "      <td>7.700157</td>\n",
       "      <td>7.885316</td>\n",
       "      <td>7.723053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>499997</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551825</td>\n",
       "      <td>0.661007</td>\n",
       "      <td>0.629606</td>\n",
       "      <td>0.714139</td>\n",
       "      <td>0.245732</td>\n",
       "      <td>8.706755</td>\n",
       "      <td>1</td>\n",
       "      <td>8.261337</td>\n",
       "      <td>8.171155</td>\n",
       "      <td>8.211826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>499998</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351036</td>\n",
       "      <td>0.288768</td>\n",
       "      <td>0.611169</td>\n",
       "      <td>0.380254</td>\n",
       "      <td>0.332030</td>\n",
       "      <td>7.229569</td>\n",
       "      <td>3</td>\n",
       "      <td>8.095134</td>\n",
       "      <td>8.106153</td>\n",
       "      <td>8.101049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>499999</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776019</td>\n",
       "      <td>0.734707</td>\n",
       "      <td>0.484392</td>\n",
       "      <td>0.639754</td>\n",
       "      <td>0.689317</td>\n",
       "      <td>8.631146</td>\n",
       "      <td>1</td>\n",
       "      <td>8.287729</td>\n",
       "      <td>8.213970</td>\n",
       "      <td>8.290882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont9  \\\n",
       "0            1    B    B    B    C    B    B    A    E    C  ...  0.267559   \n",
       "1            2    B    B    A    A    B    D    A    F    A  ...  0.341439   \n",
       "2            3    A    A    A    C    B    D    A    D    A  ...  0.843531   \n",
       "3            4    B    B    A    C    B    D    A    E    C  ...  0.574844   \n",
       "4            6    A    A    A    C    B    D    A    E    A  ...  0.956692   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "299995  499993    B    B    A    A    B    D    A    E    A  ...  0.853726   \n",
       "299996  499996    A    B    A    C    B    B    A    E    E  ...  0.433525   \n",
       "299997  499997    B    B    A    C    B    C    A    E    G  ...  0.551825   \n",
       "299998  499998    A    B    A    C    B    B    A    E    E  ...  0.351036   \n",
       "299999  499999    A    A    A    C    A    D    A    E    A  ...  0.776019   \n",
       "\n",
       "          cont10    cont11    cont12    cont13    target  kfold    pred_1  \\\n",
       "0       0.237281  0.377873  0.322401  0.869850  8.113634      0  8.445581   \n",
       "1       0.906013  0.921701  0.261975  0.465083  8.481233      2  8.374415   \n",
       "2       0.748809  0.620126  0.541474  0.763846  8.364351      4  8.195627   \n",
       "3       0.346010  0.714610  0.540150  0.280682  8.049253      3  8.388680   \n",
       "4       1.000773  0.776742  0.625849  0.250823  7.972260      1  8.258226   \n",
       "...          ...       ...       ...       ...       ...    ...       ...   \n",
       "299995  0.422541  1.063463  0.697685  0.506404  7.945605      4  8.312504   \n",
       "299996  0.301015  0.268447  0.577055  0.823611  7.326118      3  7.700157   \n",
       "299997  0.661007  0.629606  0.714139  0.245732  8.706755      1  8.261337   \n",
       "299998  0.288768  0.611169  0.380254  0.332030  7.229569      3  8.095134   \n",
       "299999  0.734707  0.484392  0.639754  0.689317  8.631146      1  8.287729   \n",
       "\n",
       "          pred_2    pred_3  \n",
       "0       8.404875  8.448442  \n",
       "1       8.277811  8.316208  \n",
       "2       8.111172  8.139681  \n",
       "3       8.305612  8.374855  \n",
       "4       8.220263  8.256620  \n",
       "...          ...       ...  \n",
       "299995  8.330939  8.255457  \n",
       "299996  7.885316  7.723053  \n",
       "299997  8.171155  8.211826  \n",
       "299998  8.106153  8.101049  \n",
       "299999  8.213970  8.290882  \n",
       "\n",
       "[300000 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:08:45.075362Z",
     "iopub.status.busy": "2021-08-25T20:08:45.075008Z",
     "iopub.status.idle": "2021-08-25T20:08:45.170836Z",
     "shell.execute_reply": "2021-08-25T20:08:45.169856Z",
     "shell.execute_reply.started": "2021-08-25T20:08:45.075325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321832</td>\n",
       "      <td>0.445212</td>\n",
       "      <td>0.290258</td>\n",
       "      <td>0.244476</td>\n",
       "      <td>0.087914</td>\n",
       "      <td>0.301831</td>\n",
       "      <td>0.845702</td>\n",
       "      <td>8.088900</td>\n",
       "      <td>8.009207</td>\n",
       "      <td>8.085726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835961</td>\n",
       "      <td>0.391657</td>\n",
       "      <td>0.288276</td>\n",
       "      <td>0.549568</td>\n",
       "      <td>0.905097</td>\n",
       "      <td>0.850684</td>\n",
       "      <td>0.693940</td>\n",
       "      <td>8.409900</td>\n",
       "      <td>8.292212</td>\n",
       "      <td>8.392296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879379</td>\n",
       "      <td>0.275549</td>\n",
       "      <td>0.427871</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.384315</td>\n",
       "      <td>0.376689</td>\n",
       "      <td>0.508099</td>\n",
       "      <td>8.427935</td>\n",
       "      <td>8.390079</td>\n",
       "      <td>8.416870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644315</td>\n",
       "      <td>1.024017</td>\n",
       "      <td>0.391090</td>\n",
       "      <td>0.988340</td>\n",
       "      <td>0.411828</td>\n",
       "      <td>0.393585</td>\n",
       "      <td>0.461372</td>\n",
       "      <td>8.518767</td>\n",
       "      <td>8.511569</td>\n",
       "      <td>8.521971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408874</td>\n",
       "      <td>0.447887</td>\n",
       "      <td>0.390253</td>\n",
       "      <td>0.648932</td>\n",
       "      <td>0.385935</td>\n",
       "      <td>0.370401</td>\n",
       "      <td>0.900412</td>\n",
       "      <td>8.164892</td>\n",
       "      <td>8.156339</td>\n",
       "      <td>8.169494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>499987</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>1.028978</td>\n",
       "      <td>1.022741</td>\n",
       "      <td>0.683903</td>\n",
       "      <td>0.877273</td>\n",
       "      <td>0.532410</td>\n",
       "      <td>0.605397</td>\n",
       "      <td>0.884581</td>\n",
       "      <td>7.996167</td>\n",
       "      <td>8.063257</td>\n",
       "      <td>8.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>499990</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359871</td>\n",
       "      <td>0.550013</td>\n",
       "      <td>0.492082</td>\n",
       "      <td>0.202295</td>\n",
       "      <td>0.416875</td>\n",
       "      <td>0.406205</td>\n",
       "      <td>0.758665</td>\n",
       "      <td>8.479431</td>\n",
       "      <td>8.399576</td>\n",
       "      <td>8.502170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>499991</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317185</td>\n",
       "      <td>0.150340</td>\n",
       "      <td>0.122109</td>\n",
       "      <td>0.390524</td>\n",
       "      <td>0.334026</td>\n",
       "      <td>0.378987</td>\n",
       "      <td>0.839416</td>\n",
       "      <td>8.473834</td>\n",
       "      <td>8.430684</td>\n",
       "      <td>8.499910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>499994</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901241</td>\n",
       "      <td>0.555339</td>\n",
       "      <td>0.844315</td>\n",
       "      <td>0.894193</td>\n",
       "      <td>0.794102</td>\n",
       "      <td>0.844279</td>\n",
       "      <td>0.890473</td>\n",
       "      <td>8.152552</td>\n",
       "      <td>8.163454</td>\n",
       "      <td>8.129901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>499995</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654738</td>\n",
       "      <td>0.574575</td>\n",
       "      <td>0.617467</td>\n",
       "      <td>0.694336</td>\n",
       "      <td>0.745698</td>\n",
       "      <td>0.568525</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>7.961390</td>\n",
       "      <td>8.032776</td>\n",
       "      <td>7.987006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont7  \\\n",
       "0            0    B    B    B    C    B    B    A    E    E  ...  0.321832   \n",
       "1            5    A    B    A    C    B    C    A    E    C  ...  0.835961   \n",
       "2           15    B    A    A    A    B    B    A    E    D  ...  0.879379   \n",
       "3           16    B    B    A    C    B    D    A    E    A  ...  0.644315   \n",
       "4           17    B    B    A    C    B    C    A    E    C  ...  0.408874   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "199995  499987    B    A    A    C    B    D    A    E    E  ...  1.028978   \n",
       "199996  499990    B    A    A    C    B    B    A    E    C  ...  0.359871   \n",
       "199997  499991    A    B    B    C    B    B    A    E    C  ...  0.317185   \n",
       "199998  499994    A    A    A    C    B    D    A    D    A  ...  0.901241   \n",
       "199999  499995    A    A    A    C    B    D    A    E    A  ...  0.654738   \n",
       "\n",
       "           cont8     cont9    cont10    cont11    cont12    cont13    pred_1  \\\n",
       "0       0.445212  0.290258  0.244476  0.087914  0.301831  0.845702  8.088900   \n",
       "1       0.391657  0.288276  0.549568  0.905097  0.850684  0.693940  8.409900   \n",
       "2       0.275549  0.427871  0.491667  0.384315  0.376689  0.508099  8.427935   \n",
       "3       1.024017  0.391090  0.988340  0.411828  0.393585  0.461372  8.518767   \n",
       "4       0.447887  0.390253  0.648932  0.385935  0.370401  0.900412  8.164892   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  1.022741  0.683903  0.877273  0.532410  0.605397  0.884581  7.996167   \n",
       "199996  0.550013  0.492082  0.202295  0.416875  0.406205  0.758665  8.479431   \n",
       "199997  0.150340  0.122109  0.390524  0.334026  0.378987  0.839416  8.473834   \n",
       "199998  0.555339  0.844315  0.894193  0.794102  0.844279  0.890473  8.152552   \n",
       "199999  0.574575  0.617467  0.694336  0.745698  0.568525  0.783568  7.961390   \n",
       "\n",
       "          pred_2    pred_3  \n",
       "0       8.009207  8.085726  \n",
       "1       8.292212  8.392296  \n",
       "2       8.390079  8.416870  \n",
       "3       8.511569  8.521971  \n",
       "4       8.156339  8.169494  \n",
       "...          ...       ...  \n",
       "199995  8.063257  8.000681  \n",
       "199996  8.399576  8.502170  \n",
       "199997  8.430684  8.499910  \n",
       "199998  8.163454  8.129901  \n",
       "199999  8.032776  7.987006  \n",
       "\n",
       "[200000 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:08:45.172531Z",
     "iopub.status.busy": "2021-08-25T20:08:45.172164Z",
     "iopub.status.idle": "2021-08-25T20:08:46.020495Z",
     "shell.execute_reply": "2021-08-25T20:08:46.019587Z",
     "shell.execute_reply.started": "2021-08-25T20:08:45.172496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7168366494082297\n",
      "1 0.7168093752166348\n",
      "2 0.7185861690748995\n",
      "3 0.7186226645301521\n",
      "4 0.7173122170066967\n",
      "0.7176334150473226 0.0008128222541052264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    X_train =  train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "\n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:08:56.075489Z",
     "iopub.status.busy": "2021-08-25T20:08:56.075148Z",
     "iopub.status.idle": "2021-08-25T20:08:56.690299Z",
     "shell.execute_reply": "2021-08-25T20:08:56.689494Z",
     "shell.execute_reply.started": "2021-08-25T20:08:56.075454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export submission.csv\n",
    "preds = np.mean(np.column_stack(final_predictions), axis=1)\n",
    "preds = pd.DataFrame({'id': sample_submission.id, 'target': preds})\n",
    "preds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T21:31:24.813254Z",
     "iopub.status.busy": "2021-08-24T21:31:24.812699Z",
     "iopub.status.idle": "2021-08-24T21:31:47.802759Z",
     "shell.execute_reply": "2021-08-24T21:31:47.801846Z",
     "shell.execute_reply.started": "2021-08-24T21:31:24.813211Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# With Standardization\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Preprocessing - Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T21:42:54.461192Z",
     "iopub.status.busy": "2021-08-24T21:42:54.460834Z",
     "iopub.status.idle": "2021-08-24T21:43:17.569538Z",
     "shell.execute_reply": "2021-08-24T21:43:17.568484Z",
     "shell.execute_reply.started": "2021-08-24T21:42:54.461157Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# With Normalization\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "\n",
    "    # Preprocessing - Normalizatino\n",
    "    normalizer = Normalizer()\n",
    "    X_train[num_cols] = normalizer.fit_transform(X_train[num_cols])\n",
    "    X_valid[num_cols] = normalizer.transform(X_valid[num_cols])\n",
    "    X_test[num_cols] = normalizer.transform(X_test[num_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T21:44:15.295451Z",
     "iopub.status.busy": "2021-08-24T21:44:15.294985Z",
     "iopub.status.idle": "2021-08-24T21:44:38.737812Z",
     "shell.execute_reply": "2021-08-24T21:44:38.736862Z",
     "shell.execute_reply.started": "2021-08-24T21:44:15.295406Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# With Standardization + Normalization\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "\n",
    "    # Preprocessing - Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n",
    "    \n",
    "    # Preprocessing - Normalizatino\n",
    "    normalizer = Normalizer()\n",
    "    X_train[num_cols] = normalizer.fit_transform(X_train[num_cols])\n",
    "    X_valid[num_cols] = normalizer.transform(X_valid[num_cols])\n",
    "    X_test[num_cols] = normalizer.transform(X_test[num_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# With Standardization\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Preprocessing - Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T21:47:08.741828Z",
     "iopub.status.busy": "2021-08-24T21:47:08.741473Z",
     "iopub.status.idle": "2021-08-24T21:47:37.645747Z",
     "shell.execute_reply": "2021-08-24T21:47:37.644785Z",
     "shell.execute_reply.started": "2021-08-24T21:47:08.741796Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Log transformation + Tuning\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "for col in num_cols:\n",
    "    train_data[col] = np.log1p(train_data[col])\n",
    "    test_data[col] = np.log1p(test_data[col])\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n",
    "                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "print('You need to reset dataframe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T22:20:02.27741Z",
     "iopub.status.busy": "2021-08-24T22:20:02.277023Z",
     "iopub.status.idle": "2021-08-24T22:20:55.762472Z",
     "shell.execute_reply": "2021-08-24T22:20:55.761626Z",
     "shell.execute_reply.started": "2021-08-24T22:20:02.277378Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# polynomial features + Tuning\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, \n",
    "                          interaction_only=True, # If true, only interaction features are produced: features that are products of at most degree distinct input features (so not x[1] ** 2, x[0] * x[2] ** 3, etc.).\n",
    "                          include_bias=False)\n",
    "train_poly = poly.fit_transform(train_data[num_cols])\n",
    "test_poly = poly.fit_transform(test_data[num_cols])\n",
    "\n",
    "df_train_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\n",
    "df_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n",
    "\n",
    "train_data = pd.concat([train_data, df_train_poly], axis=1)\n",
    "test_data = pd.concat([test_data, df_test_poly], axis=1)\n",
    "\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n",
    "                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "print('You need to reset dataframe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T22:29:42.845783Z",
     "iopub.status.busy": "2021-08-24T22:29:42.845424Z",
     "iopub.status.idle": "2021-08-24T22:29:42.932702Z",
     "shell.execute_reply": "2021-08-24T22:29:42.931612Z",
     "shell.execute_reply.started": "2021-08-24T22:29:42.845746Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T22:42:37.746908Z",
     "iopub.status.busy": "2021-08-24T22:42:37.746539Z",
     "iopub.status.idle": "2021-08-24T22:43:05.859597Z",
     "shell.execute_reply": "2021-08-24T22:43:05.857667Z",
     "shell.execute_reply.started": "2021-08-24T22:42:37.746864Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# One-Hot Encoding + Ordinal Encoding + Tuning\n",
    "# pd.cut \n",
    "# Model Tuning + drop cat2\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "oe_cols = ['cat9']\n",
    "ohe_cols = cat_cols\n",
    "ohe_cols.remove('cat9')\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[oe_cols] = ordinal_encoder.fit_transform(X_train[oe_cols])\n",
    "    X_valid[oe_cols] = ordinal_encoder.transform(X_valid[oe_cols])\n",
    "    X_test[oe_cols] = ordinal_encoder.transform(X_test[oe_cols]) # Q. The last transform\n",
    "    \n",
    "    # Preprocessing - One-Hot Encoding\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "    X_train_ohe = ohe.fit_transform(X_train[ohe_cols])\n",
    "    X_valid_ohe = ohe.transform(X_valid[ohe_cols])\n",
    "    X_test_ohe = ohe.transform(X_test[ohe_cols]) # Q. The last transform\n",
    "    \n",
    "    X_train_ohe = pd.DataFrame(X_train_ohe, columns=[f\"ohe_{i}\" for i in range(X_train_ohe.shape[1])])\n",
    "    X_valid_ohe = pd.DataFrame(X_valid_ohe, columns=[f\"ohe_{i}\" for i in range(X_valid_ohe.shape[1])])\n",
    "    X_test_ohe = pd.DataFrame(X_test_ohe, columns=[f\"ohe_{i}\" for i in range(X_test_ohe.shape[1])])\n",
    "    \n",
    "    X_train = pd.concat([X_train.drop(columns=ohe_cols), X_train_ohe], axis=1)\n",
    "    X_valid = pd.concat([X_valid.drop(columns=ohe_cols), X_valid_ohe], axis=1)\n",
    "    X_test = pd.concat([X_test.drop(columns=ohe_cols), X_test_ohe], axis=1)\n",
    "\n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n",
    "                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "print('You need to reset dataframe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T21:54:06.321743Z",
     "iopub.status.busy": "2021-08-24T21:54:06.321382Z",
     "iopub.status.idle": "2021-08-24T21:54:33.276709Z",
     "shell.execute_reply": "2021-08-24T21:54:33.275794Z",
     "shell.execute_reply.started": "2021-08-24T21:54:06.321709Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Model Tuning + drop cat2\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\", \"cat2\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n",
    "                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "print('You need to reset dataframe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T21:55:30.031587Z",
     "iopub.status.busy": "2021-08-24T21:55:30.031254Z",
     "iopub.status.idle": "2021-08-24T21:55:54.609825Z",
     "shell.execute_reply": "2021-08-24T21:55:54.608783Z",
     "shell.execute_reply.started": "2021-08-24T21:55:30.031558Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Model Tuning + drop cat2, cat6\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\", \"cat2\", \"cat6\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n",
    "                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "print('You need to reset dataframe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T22:31:05.898981Z",
     "iopub.status.busy": "2021-08-24T22:31:05.89861Z",
     "iopub.status.idle": "2021-08-24T22:31:33.912625Z",
     "shell.execute_reply": "2021-08-24T22:31:33.911724Z",
     "shell.execute_reply.started": "2021-08-24T22:31:05.898945Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tuning + Standardization\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Preprocessing - Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n",
    "                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T21:50:43.551835Z",
     "iopub.status.busy": "2021-08-24T21:50:43.55151Z",
     "iopub.status.idle": "2021-08-24T21:51:12.086803Z",
     "shell.execute_reply": "2021-08-24T21:51:12.085859Z",
     "shell.execute_reply.started": "2021-08-24T21:50:43.551803Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Only Model Tuning\n",
    "useful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\n",
    "cat_cols = [col for col in useful_features if \"cat\" in col]\n",
    "num_cols = [col for col in useful_features if col.startswith('cont')]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Preprocessing - Kfold\n",
    "    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "    \n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    # Preprocessing - Ordinal Encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n",
    "    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n",
    "    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n",
    "    \n",
    "    # Training\n",
    "    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n",
    "    #model = XGBRegressor(random_state=fold, n_jobs=8)\n",
    "    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n",
    "                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    \n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T21:48:43.960328Z",
     "iopub.status.busy": "2021-08-24T21:48:43.959974Z",
     "iopub.status.idle": "2021-08-24T21:48:44.474981Z",
     "shell.execute_reply": "2021-08-24T21:48:44.474102Z",
     "shell.execute_reply.started": "2021-08-24T21:48:43.960296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export submission.csv\n",
    "preds = np.mean(np.column_stack(final_predictions), axis=1)\n",
    "preds = pd.DataFrame({'id': sample_submission.id, 'target': preds})\n",
    "preds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
