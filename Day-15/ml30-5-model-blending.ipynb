{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Statistics\nimport pandas as pd\nimport numpy as np\nimport math as mt\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Data Preprocessing - Standardization, Encoding, Imputation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\n\n\n# Data Preprocessing - Feature Engineering\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.decomposition import PCA\n\n# Data Preprocessing - ML Pipelines\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n# ML - Modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\n# ML - Evaluation\nfrom sklearn.model_selection import cross_val_score\n\n# ML - Tuning\nfrom sklearn.model_selection import GridSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-25T19:53:01.337608Z","iopub.execute_input":"2021-08-25T19:53:01.337983Z","iopub.status.idle":"2021-08-25T19:53:02.489733Z","shell.execute_reply.started":"2021-08-25T19:53:01.337918Z","shell.execute_reply":"2021-08-25T19:53:02.488888Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/30-days-of-ml/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T19:53:09.283812Z","iopub.execute_input":"2021-08-25T19:53:09.284133Z","iopub.status.idle":"2021-08-25T19:53:09.374021Z","shell.execute_reply.started":"2021-08-25T19:53:09.284102Z","shell.execute_reply":"2021-08-25T19:53:09.373250Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"%%time\n# Baseline\ntrain_data = pd.read_csv('../input/30days-folds/train_folds.csv')\ntest_data = pd.read_csv('../input/30-days-of-ml/test.csv')\n\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\ntest_data = test_data[useful_features]\n\nfinal_valid_predictions = {}\nfinal_test_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    X_valid_ids = X_valid.id.values.tolist()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 10000,\n        'learning_rate': 0.03628302216953097,\n        'reg_lambda': 0.0008746338866473539,\n        'reg_alpha': 23.13181079976304,\n        'subsample': 0.7875490025178415,\n        'colsample_bytree': 0.11807135201147481,\n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        tree_method='gpu_hist', \n        gpu_id=0, \n        predictor='gpu_predictor',\n        **params\n    )\n    model.fit(X_train, y_train, early_stopping_rounds=300, eval_set=[(X_valid, y_valid)], verbose=1000)\n    \n    # Evaluation and Inference\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    \n    final_valid_predictions.update(dict(zip(X_valid_ids, preds_valid)))\n    final_test_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"train_pred_1.csv\", index=False)\n\npreds = np.mean(np.column_stack(final_test_predictions), axis=1)\npreds = pd.DataFrame({'id': sample_submission.id, 'pred_1': preds})\npreds.to_csv(\"test_pred_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T19:58:35.562727Z","iopub.execute_input":"2021-08-25T19:58:35.563049Z","iopub.status.idle":"2021-08-25T20:00:38.923128Z","shell.execute_reply.started":"2021-08-25T19:58:35.563018Z","shell.execute_reply":"2021-08-25T20:00:38.922219Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:7.50031\n[1000]\tvalidation_0-rmse:0.72395\n[2000]\tvalidation_0-rmse:0.72000\n[3000]\tvalidation_0-rmse:0.71849\n[4000]\tvalidation_0-rmse:0.71770\n[5000]\tvalidation_0-rmse:0.71730\n[6000]\tvalidation_0-rmse:0.71705\n[7000]\tvalidation_0-rmse:0.71693\n[8000]\tvalidation_0-rmse:0.71688\n[8522]\tvalidation_0-rmse:0.71687\n0 0.7168573307459428\n[0]\tvalidation_0-rmse:7.49707\n[1000]\tvalidation_0-rmse:0.72356\n[2000]\tvalidation_0-rmse:0.71967\n[3000]\tvalidation_0-rmse:0.71825\n[4000]\tvalidation_0-rmse:0.71751\n[5000]\tvalidation_0-rmse:0.71714\n[6000]\tvalidation_0-rmse:0.71696\n[7000]\tvalidation_0-rmse:0.71688\n[8000]\tvalidation_0-rmse:0.71682\n[8063]\tvalidation_0-rmse:0.71681\n1 0.7168120224667079\n[0]\tvalidation_0-rmse:7.49474\n[1000]\tvalidation_0-rmse:0.72527\n[2000]\tvalidation_0-rmse:0.72145\n[3000]\tvalidation_0-rmse:0.71996\n[4000]\tvalidation_0-rmse:0.71932\n[5000]\tvalidation_0-rmse:0.71894\n[6000]\tvalidation_0-rmse:0.71872\n[7000]\tvalidation_0-rmse:0.71863\n[7931]\tvalidation_0-rmse:0.71862\n2 0.7185994471569308\n[0]\tvalidation_0-rmse:7.49705\n[1000]\tvalidation_0-rmse:0.72544\n[2000]\tvalidation_0-rmse:0.72153\n[3000]\tvalidation_0-rmse:0.72008\n[4000]\tvalidation_0-rmse:0.71939\n[5000]\tvalidation_0-rmse:0.71899\n[6000]\tvalidation_0-rmse:0.71882\n[7000]\tvalidation_0-rmse:0.71871\n[8000]\tvalidation_0-rmse:0.71864\n[9000]\tvalidation_0-rmse:0.71862\n[9187]\tvalidation_0-rmse:0.71862\n3 0.7186056377572814\n[0]\tvalidation_0-rmse:7.50250\n[1000]\tvalidation_0-rmse:0.72479\n[2000]\tvalidation_0-rmse:0.72049\n[3000]\tvalidation_0-rmse:0.71881\n[4000]\tvalidation_0-rmse:0.71799\n[5000]\tvalidation_0-rmse:0.71753\n[6000]\tvalidation_0-rmse:0.71734\n[7000]\tvalidation_0-rmse:0.71724\n[7615]\tvalidation_0-rmse:0.71721\n4 0.7172010858995527\n0.7176151048052831 0.0008173933956283648\nCPU times: user 2min 2s, sys: 1.36 s, total: 2min 3s\nWall time: 2min 3s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n# Model 2 polynominal features\ntrain_data = pd.read_csv('../input/30days-folds/train_folds.csv')\ntest_data = pd.read_csv('../input/30-days-of-ml/test.csv')\n\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith(\"cont\")]\ntest_data = test_data[useful_features]\n\npoly = PolynomialFeatures(degree=3, \n                          interaction_only=True, # If true, only interaction features are produced: features that are products of at most degree distinct input features (so not x[1] ** 2, x[0] * x[2] ** 3, etc.).\n                          include_bias=False)\ntrain_poly = poly.fit_transform(train_data[num_cols])\ntest_poly = poly.fit_transform(test_data[num_cols])\n\ndf_train_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\ndf_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n\ntrain_data = pd.concat([train_data, df_train_poly], axis=1)\ntest_data = pd.concat([test_data, df_test_poly], axis=1)\n\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\ntest_data = test_data[useful_features]\n\nfinal_valid_predictions = {}\nfinal_test_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    X_valid_ids = X_valid.id.values.tolist()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 10000,\n        'learning_rate': 0.03628302216953097,\n        'reg_lambda': 0.0008746338866473539,\n        'reg_alpha': 23.13181079976304,\n        'subsample': 0.7875490025178415,\n        'colsample_bytree': 0.11807135201147481,\n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        tree_method='gpu_hist', \n        gpu_id=0, \n        predictor='gpu_predictor',\n        **params\n    )\n    model.fit(X_train, y_train, early_stopping_rounds=300, eval_set=[(X_valid, y_valid)], verbose=1000)\n    \n    # Evaluation and Inference\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    \n    final_valid_predictions.update(dict(zip(X_valid_ids, preds_valid)))\n    final_test_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_2\"]\nfinal_valid_predictions.to_csv(\"train_pred_2.csv\", index=False)\n\npreds = np.mean(np.column_stack(final_test_predictions), axis=1)\npreds = pd.DataFrame({'id': sample_submission.id, 'pred_2': preds})\npreds.to_csv(\"test_pred_2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:00:38.924685Z","iopub.execute_input":"2021-08-25T20:00:38.925182Z","iopub.status.idle":"2021-08-25T20:06:29.281949Z","shell.execute_reply.started":"2021-08-25T20:00:38.925143Z","shell.execute_reply":"2021-08-25T20:06:29.281068Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:7.50030\n[1000]\tvalidation_0-rmse:0.72375\n[2000]\tvalidation_0-rmse:0.72144\n[3000]\tvalidation_0-rmse:0.72094\n[4000]\tvalidation_0-rmse:0.72078\n[4261]\tvalidation_0-rmse:0.72083\n0 0.720767827951469\n[0]\tvalidation_0-rmse:7.49705\n[1000]\tvalidation_0-rmse:0.72352\n[2000]\tvalidation_0-rmse:0.72124\n[3000]\tvalidation_0-rmse:0.72064\n[4000]\tvalidation_0-rmse:0.72047\n[4219]\tvalidation_0-rmse:0.72045\n1 0.7204373982348939\n[0]\tvalidation_0-rmse:7.49473\n[1000]\tvalidation_0-rmse:0.72539\n[2000]\tvalidation_0-rmse:0.72322\n[3000]\tvalidation_0-rmse:0.72267\n[3851]\tvalidation_0-rmse:0.72263\n2 0.7225806933088028\n[0]\tvalidation_0-rmse:7.49707\n[1000]\tvalidation_0-rmse:0.72515\n[2000]\tvalidation_0-rmse:0.72277\n[3000]\tvalidation_0-rmse:0.72218\n[3625]\tvalidation_0-rmse:0.72220\n3 0.72214507339082\n[0]\tvalidation_0-rmse:7.50251\n[1000]\tvalidation_0-rmse:0.72449\n[2000]\tvalidation_0-rmse:0.72208\n[3000]\tvalidation_0-rmse:0.72151\n[3571]\tvalidation_0-rmse:0.72143\n4 0.7214106603740207\n0.7214683306520013 0.0008064964919760797\nCPU times: user 5min 45s, sys: 15.3 s, total: 6min\nWall time: 5min 50s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n# Model 3 targeting encoding\ntrain_data = pd.read_csv('../input/30days-folds/train_folds.csv')\ntest_data = pd.read_csv('../input/30-days-of-ml/test.csv')\n\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\ntest_data = test_data[useful_features]\n\nfor col in cat_cols:\n    temp_df = []\n    temp_test_feat = None\n    for fold in range(5):\n        X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n        X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n        feat = X_train.groupby(col)[\"target\"].agg(\"mean\")\n        feat = feat.to_dict()\n        #print(feat)\n        X_valid.loc[:, f\"tar_enc_{col}\"] = X_valid[col].map(feat)\n        temp_df.append(X_valid)\n        if temp_test_feat is None:\n            temp_test_feat = test_data[col].map(feat)\n        else:\n            temp_test_feat += test_data[col].map(feat)\n\n    temp_test_feat /= 5\n    test_data.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n    train_data = pd.concat(temp_df)\n    \nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if col.startswith(\"cat\")]\ntest_data = test_data[useful_features]\n\n\nfinal_valid_predictions = {}\nfinal_test_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    X_valid_ids = X_valid.id.values.tolist()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 10000,\n        'learning_rate': 0.03628302216953097,\n        'reg_lambda': 0.0008746338866473539,\n        'reg_alpha': 23.13181079976304,\n        'subsample': 0.7875490025178415,\n        'colsample_bytree': 0.11807135201147481,\n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        tree_method='gpu_hist', \n        gpu_id=0, \n        predictor='gpu_predictor',\n        **params\n    )\n    model.fit(X_train, y_train, early_stopping_rounds=300, eval_set=[(X_valid, y_valid)], verbose=1000)\n    \n    # Evaluation and Inference\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    \n    final_valid_predictions.update(dict(zip(X_valid_ids, preds_valid)))\n    final_test_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_3\"]\nfinal_valid_predictions.to_csv(\"train_pred_3.csv\", index=False)\n\npreds = np.mean(np.column_stack(final_test_predictions), axis=1)\npreds = pd.DataFrame({'id': sample_submission.id, 'pred_3': preds})\npreds.to_csv(\"test_pred_3.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:06:29.283816Z","iopub.execute_input":"2021-08-25T20:06:29.284305Z","iopub.status.idle":"2021-08-25T20:08:42.539299Z","shell.execute_reply.started":"2021-08-25T20:06:29.284265Z","shell.execute_reply":"2021-08-25T20:08:42.538463Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:7.50029\n[1000]\tvalidation_0-rmse:0.72337\n[2000]\tvalidation_0-rmse:0.71989\n[3000]\tvalidation_0-rmse:0.71849\n[4000]\tvalidation_0-rmse:0.71785\n[5000]\tvalidation_0-rmse:0.71751\n[6000]\tvalidation_0-rmse:0.71737\n[7000]\tvalidation_0-rmse:0.71730\n[7745]\tvalidation_0-rmse:0.71730\n0 0.7172629713248143\n[0]\tvalidation_0-rmse:7.49700\n[1000]\tvalidation_0-rmse:0.72288\n[2000]\tvalidation_0-rmse:0.71932\n[3000]\tvalidation_0-rmse:0.71804\n[4000]\tvalidation_0-rmse:0.71753\n[5000]\tvalidation_0-rmse:0.71726\n[6000]\tvalidation_0-rmse:0.71708\n[7000]\tvalidation_0-rmse:0.71695\n[7404]\tvalidation_0-rmse:0.71696\n1 0.7169390974696654\n[0]\tvalidation_0-rmse:7.49478\n[1000]\tvalidation_0-rmse:0.72462\n[2000]\tvalidation_0-rmse:0.72122\n[3000]\tvalidation_0-rmse:0.71988\n[4000]\tvalidation_0-rmse:0.71934\n[5000]\tvalidation_0-rmse:0.71904\n[6000]\tvalidation_0-rmse:0.71898\n[6760]\tvalidation_0-rmse:0.71897\n2 0.7189471800619452\n[0]\tvalidation_0-rmse:7.49701\n[1000]\tvalidation_0-rmse:0.72454\n[2000]\tvalidation_0-rmse:0.72114\n[3000]\tvalidation_0-rmse:0.71985\n[4000]\tvalidation_0-rmse:0.71932\n[5000]\tvalidation_0-rmse:0.71907\n[6000]\tvalidation_0-rmse:0.71893\n[7000]\tvalidation_0-rmse:0.71886\n[8000]\tvalidation_0-rmse:0.71883\n[8188]\tvalidation_0-rmse:0.71884\n3 0.7188212602389504\n[0]\tvalidation_0-rmse:7.50245\n[1000]\tvalidation_0-rmse:0.72475\n[2000]\tvalidation_0-rmse:0.72099\n[3000]\tvalidation_0-rmse:0.71957\n[4000]\tvalidation_0-rmse:0.71905\n[5000]\tvalidation_0-rmse:0.71880\n[5629]\tvalidation_0-rmse:0.71876\n4 0.7187469985550542\n0.718143501530086 0.000859696143100782\nCPU times: user 2min 12s, sys: 1.9 s, total: 2min 14s\nWall time: 2min 13s\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/30days-folds/train_folds.csv')\ntest_data = pd.read_csv('../input/30-days-of-ml/test.csv')\n\ndf_train1 = pd.read_csv('train_pred_1.csv')\ndf_train2 = pd.read_csv('train_pred_2.csv')\ndf_train3 = pd.read_csv('train_pred_3.csv')\n\ndf_test1 = pd.read_csv('test_pred_1.csv')\ndf_test2 = pd.read_csv('test_pred_2.csv')\ndf_test3 = pd.read_csv('test_pred_3.csv')\n\ntrain_data = train_data.merge(df_train1, on=\"id\", how=\"left\")\ntrain_data = train_data.merge(df_train2, on=\"id\", how=\"left\")\ntrain_data = train_data.merge(df_train3, on=\"id\", how=\"left\")\n\ntest_data = test_data.merge(df_test1, on=\"id\", how=\"left\")\ntest_data = test_data.merge(df_test2, on=\"id\", how=\"left\")\ntest_data = test_data.merge(df_test3, on=\"id\", how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:08:42.540934Z","iopub.execute_input":"2021-08-25T20:08:42.541271Z","iopub.status.idle":"2021-08-25T20:08:44.932556Z","shell.execute_reply.started":"2021-08-25T20:08:42.541236Z","shell.execute_reply":"2021-08-25T20:08:44.931680Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:08:44.933867Z","iopub.execute_input":"2021-08-25T20:08:44.934219Z","iopub.status.idle":"2021-08-25T20:08:45.073625Z","shell.execute_reply.started":"2021-08-25T20:08:44.934185Z","shell.execute_reply":"2021-08-25T20:08:45.072637Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont9  \\\n0            1    B    B    B    C    B    B    A    E    C  ...  0.267559   \n1            2    B    B    A    A    B    D    A    F    A  ...  0.341439   \n2            3    A    A    A    C    B    D    A    D    A  ...  0.843531   \n3            4    B    B    A    C    B    D    A    E    C  ...  0.574844   \n4            6    A    A    A    C    B    D    A    E    A  ...  0.956692   \n...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n299995  499993    B    B    A    A    B    D    A    E    A  ...  0.853726   \n299996  499996    A    B    A    C    B    B    A    E    E  ...  0.433525   \n299997  499997    B    B    A    C    B    C    A    E    G  ...  0.551825   \n299998  499998    A    B    A    C    B    B    A    E    E  ...  0.351036   \n299999  499999    A    A    A    C    A    D    A    E    A  ...  0.776019   \n\n          cont10    cont11    cont12    cont13    target  kfold    pred_1  \\\n0       0.237281  0.377873  0.322401  0.869850  8.113634      0  8.445581   \n1       0.906013  0.921701  0.261975  0.465083  8.481233      2  8.374415   \n2       0.748809  0.620126  0.541474  0.763846  8.364351      4  8.195627   \n3       0.346010  0.714610  0.540150  0.280682  8.049253      3  8.388680   \n4       1.000773  0.776742  0.625849  0.250823  7.972260      1  8.258226   \n...          ...       ...       ...       ...       ...    ...       ...   \n299995  0.422541  1.063463  0.697685  0.506404  7.945605      4  8.312504   \n299996  0.301015  0.268447  0.577055  0.823611  7.326118      3  7.700157   \n299997  0.661007  0.629606  0.714139  0.245732  8.706755      1  8.261337   \n299998  0.288768  0.611169  0.380254  0.332030  7.229569      3  8.095134   \n299999  0.734707  0.484392  0.639754  0.689317  8.631146      1  8.287729   \n\n          pred_2    pred_3  \n0       8.404875  8.448442  \n1       8.277811  8.316208  \n2       8.111172  8.139681  \n3       8.305612  8.374855  \n4       8.220263  8.256620  \n...          ...       ...  \n299995  8.330939  8.255457  \n299996  7.885316  7.723053  \n299997  8.171155  8.211826  \n299998  8.106153  8.101049  \n299999  8.213970  8.290882  \n\n[300000 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>target</th>\n      <th>kfold</th>\n      <th>pred_1</th>\n      <th>pred_2</th>\n      <th>pred_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.267559</td>\n      <td>0.237281</td>\n      <td>0.377873</td>\n      <td>0.322401</td>\n      <td>0.869850</td>\n      <td>8.113634</td>\n      <td>0</td>\n      <td>8.445581</td>\n      <td>8.404875</td>\n      <td>8.448442</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>F</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.341439</td>\n      <td>0.906013</td>\n      <td>0.921701</td>\n      <td>0.261975</td>\n      <td>0.465083</td>\n      <td>8.481233</td>\n      <td>2</td>\n      <td>8.374415</td>\n      <td>8.277811</td>\n      <td>8.316208</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>D</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.843531</td>\n      <td>0.748809</td>\n      <td>0.620126</td>\n      <td>0.541474</td>\n      <td>0.763846</td>\n      <td>8.364351</td>\n      <td>4</td>\n      <td>8.195627</td>\n      <td>8.111172</td>\n      <td>8.139681</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.574844</td>\n      <td>0.346010</td>\n      <td>0.714610</td>\n      <td>0.540150</td>\n      <td>0.280682</td>\n      <td>8.049253</td>\n      <td>3</td>\n      <td>8.388680</td>\n      <td>8.305612</td>\n      <td>8.374855</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.956692</td>\n      <td>1.000773</td>\n      <td>0.776742</td>\n      <td>0.625849</td>\n      <td>0.250823</td>\n      <td>7.972260</td>\n      <td>1</td>\n      <td>8.258226</td>\n      <td>8.220263</td>\n      <td>8.256620</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>499993</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.853726</td>\n      <td>0.422541</td>\n      <td>1.063463</td>\n      <td>0.697685</td>\n      <td>0.506404</td>\n      <td>7.945605</td>\n      <td>4</td>\n      <td>8.312504</td>\n      <td>8.330939</td>\n      <td>8.255457</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>499996</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>...</td>\n      <td>0.433525</td>\n      <td>0.301015</td>\n      <td>0.268447</td>\n      <td>0.577055</td>\n      <td>0.823611</td>\n      <td>7.326118</td>\n      <td>3</td>\n      <td>7.700157</td>\n      <td>7.885316</td>\n      <td>7.723053</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>499997</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>C</td>\n      <td>A</td>\n      <td>E</td>\n      <td>G</td>\n      <td>...</td>\n      <td>0.551825</td>\n      <td>0.661007</td>\n      <td>0.629606</td>\n      <td>0.714139</td>\n      <td>0.245732</td>\n      <td>8.706755</td>\n      <td>1</td>\n      <td>8.261337</td>\n      <td>8.171155</td>\n      <td>8.211826</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>499998</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>...</td>\n      <td>0.351036</td>\n      <td>0.288768</td>\n      <td>0.611169</td>\n      <td>0.380254</td>\n      <td>0.332030</td>\n      <td>7.229569</td>\n      <td>3</td>\n      <td>8.095134</td>\n      <td>8.106153</td>\n      <td>8.101049</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>499999</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>A</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.776019</td>\n      <td>0.734707</td>\n      <td>0.484392</td>\n      <td>0.639754</td>\n      <td>0.689317</td>\n      <td>8.631146</td>\n      <td>1</td>\n      <td>8.287729</td>\n      <td>8.213970</td>\n      <td>8.290882</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:08:45.075008Z","iopub.execute_input":"2021-08-25T20:08:45.075362Z","iopub.status.idle":"2021-08-25T20:08:45.170836Z","shell.execute_reply.started":"2021-08-25T20:08:45.075325Z","shell.execute_reply":"2021-08-25T20:08:45.169856Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont7  \\\n0            0    B    B    B    C    B    B    A    E    E  ...  0.321832   \n1            5    A    B    A    C    B    C    A    E    C  ...  0.835961   \n2           15    B    A    A    A    B    B    A    E    D  ...  0.879379   \n3           16    B    B    A    C    B    D    A    E    A  ...  0.644315   \n4           17    B    B    A    C    B    C    A    E    C  ...  0.408874   \n...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n199995  499987    B    A    A    C    B    D    A    E    E  ...  1.028978   \n199996  499990    B    A    A    C    B    B    A    E    C  ...  0.359871   \n199997  499991    A    B    B    C    B    B    A    E    C  ...  0.317185   \n199998  499994    A    A    A    C    B    D    A    D    A  ...  0.901241   \n199999  499995    A    A    A    C    B    D    A    E    A  ...  0.654738   \n\n           cont8     cont9    cont10    cont11    cont12    cont13    pred_1  \\\n0       0.445212  0.290258  0.244476  0.087914  0.301831  0.845702  8.088900   \n1       0.391657  0.288276  0.549568  0.905097  0.850684  0.693940  8.409900   \n2       0.275549  0.427871  0.491667  0.384315  0.376689  0.508099  8.427935   \n3       1.024017  0.391090  0.988340  0.411828  0.393585  0.461372  8.518767   \n4       0.447887  0.390253  0.648932  0.385935  0.370401  0.900412  8.164892   \n...          ...       ...       ...       ...       ...       ...       ...   \n199995  1.022741  0.683903  0.877273  0.532410  0.605397  0.884581  7.996167   \n199996  0.550013  0.492082  0.202295  0.416875  0.406205  0.758665  8.479431   \n199997  0.150340  0.122109  0.390524  0.334026  0.378987  0.839416  8.473834   \n199998  0.555339  0.844315  0.894193  0.794102  0.844279  0.890473  8.152552   \n199999  0.574575  0.617467  0.694336  0.745698  0.568525  0.783568  7.961390   \n\n          pred_2    pred_3  \n0       8.009207  8.085726  \n1       8.292212  8.392296  \n2       8.390079  8.416870  \n3       8.511569  8.521971  \n4       8.156339  8.169494  \n...          ...       ...  \n199995  8.063257  8.000681  \n199996  8.399576  8.502170  \n199997  8.430684  8.499910  \n199998  8.163454  8.129901  \n199999  8.032776  7.987006  \n\n[200000 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>...</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>pred_1</th>\n      <th>pred_2</th>\n      <th>pred_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>B</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>...</td>\n      <td>0.321832</td>\n      <td>0.445212</td>\n      <td>0.290258</td>\n      <td>0.244476</td>\n      <td>0.087914</td>\n      <td>0.301831</td>\n      <td>0.845702</td>\n      <td>8.088900</td>\n      <td>8.009207</td>\n      <td>8.085726</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>C</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.835961</td>\n      <td>0.391657</td>\n      <td>0.288276</td>\n      <td>0.549568</td>\n      <td>0.905097</td>\n      <td>0.850684</td>\n      <td>0.693940</td>\n      <td>8.409900</td>\n      <td>8.292212</td>\n      <td>8.392296</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>D</td>\n      <td>...</td>\n      <td>0.879379</td>\n      <td>0.275549</td>\n      <td>0.427871</td>\n      <td>0.491667</td>\n      <td>0.384315</td>\n      <td>0.376689</td>\n      <td>0.508099</td>\n      <td>8.427935</td>\n      <td>8.390079</td>\n      <td>8.416870</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.644315</td>\n      <td>1.024017</td>\n      <td>0.391090</td>\n      <td>0.988340</td>\n      <td>0.411828</td>\n      <td>0.393585</td>\n      <td>0.461372</td>\n      <td>8.518767</td>\n      <td>8.511569</td>\n      <td>8.521971</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>C</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.408874</td>\n      <td>0.447887</td>\n      <td>0.390253</td>\n      <td>0.648932</td>\n      <td>0.385935</td>\n      <td>0.370401</td>\n      <td>0.900412</td>\n      <td>8.164892</td>\n      <td>8.156339</td>\n      <td>8.169494</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>499987</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>...</td>\n      <td>1.028978</td>\n      <td>1.022741</td>\n      <td>0.683903</td>\n      <td>0.877273</td>\n      <td>0.532410</td>\n      <td>0.605397</td>\n      <td>0.884581</td>\n      <td>7.996167</td>\n      <td>8.063257</td>\n      <td>8.000681</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>499990</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.359871</td>\n      <td>0.550013</td>\n      <td>0.492082</td>\n      <td>0.202295</td>\n      <td>0.416875</td>\n      <td>0.406205</td>\n      <td>0.758665</td>\n      <td>8.479431</td>\n      <td>8.399576</td>\n      <td>8.502170</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>499991</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>...</td>\n      <td>0.317185</td>\n      <td>0.150340</td>\n      <td>0.122109</td>\n      <td>0.390524</td>\n      <td>0.334026</td>\n      <td>0.378987</td>\n      <td>0.839416</td>\n      <td>8.473834</td>\n      <td>8.430684</td>\n      <td>8.499910</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>499994</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>D</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.901241</td>\n      <td>0.555339</td>\n      <td>0.844315</td>\n      <td>0.894193</td>\n      <td>0.794102</td>\n      <td>0.844279</td>\n      <td>0.890473</td>\n      <td>8.152552</td>\n      <td>8.163454</td>\n      <td>8.129901</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>499995</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>...</td>\n      <td>0.654738</td>\n      <td>0.574575</td>\n      <td>0.617467</td>\n      <td>0.694336</td>\n      <td>0.745698</td>\n      <td>0.568525</td>\n      <td>0.783568</td>\n      <td>7.961390</td>\n      <td>8.032776</td>\n      <td>7.987006</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    X_train =  train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n\n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    \n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:08:45.172164Z","iopub.execute_input":"2021-08-25T20:08:45.172531Z","iopub.status.idle":"2021-08-25T20:08:46.020495Z","shell.execute_reply.started":"2021-08-25T20:08:45.172496Z","shell.execute_reply":"2021-08-25T20:08:46.019587Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0 0.7168366494082297\n1 0.7168093752166348\n2 0.7185861690748995\n3 0.7186226645301521\n4 0.7173122170066967\n0.7176334150473226 0.0008128222541052264\n","output_type":"stream"}]},{"cell_type":"code","source":"# Export submission.csv\npreds = np.mean(np.column_stack(final_predictions), axis=1)\npreds = pd.DataFrame({'id': sample_submission.id, 'target': preds})\npreds.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:08:56.075148Z","iopub.execute_input":"2021-08-25T20:08:56.075489Z","iopub.status.idle":"2021-08-25T20:08:56.690299Z","shell.execute_reply.started":"2021-08-25T20:08:56.075454Z","shell.execute_reply":"2021-08-25T20:08:56.689494Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# With Standardization\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Preprocessing - Standardization\n    scaler = StandardScaler()\n    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:31:24.812699Z","iopub.execute_input":"2021-08-24T21:31:24.813254Z","iopub.status.idle":"2021-08-24T21:31:47.802759Z","shell.execute_reply.started":"2021-08-24T21:31:24.813211Z","shell.execute_reply":"2021-08-24T21:31:47.801846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# With Normalization\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n\n    # Preprocessing - Normalizatino\n    normalizer = Normalizer()\n    X_train[num_cols] = normalizer.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = normalizer.transform(X_valid[num_cols])\n    X_test[num_cols] = normalizer.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:42:54.460834Z","iopub.execute_input":"2021-08-24T21:42:54.461192Z","iopub.status.idle":"2021-08-24T21:43:17.569538Z","shell.execute_reply.started":"2021-08-24T21:42:54.461157Z","shell.execute_reply":"2021-08-24T21:43:17.568484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# With Standardization + Normalization\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n\n    # Preprocessing - Standardization\n    scaler = StandardScaler()\n    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Preprocessing - Normalizatino\n    normalizer = Normalizer()\n    X_train[num_cols] = normalizer.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = normalizer.transform(X_valid[num_cols])\n    X_test[num_cols] = normalizer.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:44:15.294985Z","iopub.execute_input":"2021-08-24T21:44:15.295451Z","iopub.status.idle":"2021-08-24T21:44:38.737812Z","shell.execute_reply.started":"2021-08-24T21:44:15.295406Z","shell.execute_reply":"2021-08-24T21:44:38.736862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# With Standardization\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Preprocessing - Standardization\n    scaler = StandardScaler()\n    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Log transformation + Tuning\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfor col in num_cols:\n    train_data[col] = np.log1p(train_data[col])\n    test_data[col] = np.log1p(test_data[col])\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:47:08.741473Z","iopub.execute_input":"2021-08-24T21:47:08.741828Z","iopub.status.idle":"2021-08-24T21:47:37.645747Z","shell.execute_reply.started":"2021-08-24T21:47:08.741796Z","shell.execute_reply":"2021-08-24T21:47:37.644785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# polynomial features + Tuning\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\npoly = PolynomialFeatures(degree=2, \n                          interaction_only=True, # If true, only interaction features are produced: features that are products of at most degree distinct input features (so not x[1] ** 2, x[0] * x[2] ** 3, etc.).\n                          include_bias=False)\ntrain_poly = poly.fit_transform(train_data[num_cols])\ntest_poly = poly.fit_transform(test_data[num_cols])\n\ndf_train_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\ndf_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n\ntrain_data = pd.concat([train_data, df_train_poly], axis=1)\ntest_data = pd.concat([test_data, df_test_poly], axis=1)\n\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:20:02.277023Z","iopub.execute_input":"2021-08-24T22:20:02.27741Z","iopub.status.idle":"2021-08-24T22:20:55.762472Z","shell.execute_reply.started":"2021-08-24T22:20:02.277378Z","shell.execute_reply":"2021-08-24T22:20:55.761626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:29:42.845424Z","iopub.execute_input":"2021-08-24T22:29:42.845783Z","iopub.status.idle":"2021-08-24T22:29:42.932702Z","shell.execute_reply.started":"2021-08-24T22:29:42.845746Z","shell.execute_reply":"2021-08-24T22:29:42.931612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# One-Hot Encoding + Ordinal Encoding + Tuning\n# pd.cut \n# Model Tuning + drop cat2\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\noe_cols = ['cat9']\nohe_cols = cat_cols\nohe_cols.remove('cat9')\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[oe_cols] = ordinal_encoder.fit_transform(X_train[oe_cols])\n    X_valid[oe_cols] = ordinal_encoder.transform(X_valid[oe_cols])\n    X_test[oe_cols] = ordinal_encoder.transform(X_test[oe_cols]) # Q. The last transform\n    \n    # Preprocessing - One-Hot Encoding\n    ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n    X_train_ohe = ohe.fit_transform(X_train[ohe_cols])\n    X_valid_ohe = ohe.transform(X_valid[ohe_cols])\n    X_test_ohe = ohe.transform(X_test[ohe_cols]) # Q. The last transform\n    \n    X_train_ohe = pd.DataFrame(X_train_ohe, columns=[f\"ohe_{i}\" for i in range(X_train_ohe.shape[1])])\n    X_valid_ohe = pd.DataFrame(X_valid_ohe, columns=[f\"ohe_{i}\" for i in range(X_valid_ohe.shape[1])])\n    X_test_ohe = pd.DataFrame(X_test_ohe, columns=[f\"ohe_{i}\" for i in range(X_test_ohe.shape[1])])\n    \n    X_train = pd.concat([X_train.drop(columns=ohe_cols), X_train_ohe], axis=1)\n    X_valid = pd.concat([X_valid.drop(columns=ohe_cols), X_valid_ohe], axis=1)\n    X_test = pd.concat([X_test.drop(columns=ohe_cols), X_test_ohe], axis=1)\n\n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:42:37.746539Z","iopub.execute_input":"2021-08-24T22:42:37.746908Z","iopub.status.idle":"2021-08-24T22:43:05.859597Z","shell.execute_reply.started":"2021-08-24T22:42:37.746864Z","shell.execute_reply":"2021-08-24T22:43:05.857667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Model Tuning + drop cat2\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\", \"cat2\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:54:06.321382Z","iopub.execute_input":"2021-08-24T21:54:06.321743Z","iopub.status.idle":"2021-08-24T21:54:33.276709Z","shell.execute_reply.started":"2021-08-24T21:54:06.321709Z","shell.execute_reply":"2021-08-24T21:54:33.275794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Model Tuning + drop cat2, cat6\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\", \"cat2\", \"cat6\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nprint('You need to reset dataframe!')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:55:30.031254Z","iopub.execute_input":"2021-08-24T21:55:30.031587Z","iopub.status.idle":"2021-08-24T21:55:54.609825Z","shell.execute_reply.started":"2021-08-24T21:55:30.031558Z","shell.execute_reply":"2021-08-24T21:55:54.608783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Tuning + Standardization\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Preprocessing - Standardization\n    scaler = StandardScaler()\n    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n    X_test[num_cols] = scaler.transform(X_test[num_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    #model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T22:31:05.89861Z","iopub.execute_input":"2021-08-24T22:31:05.898981Z","iopub.status.idle":"2021-08-24T22:31:33.912625Z","shell.execute_reply.started":"2021-08-24T22:31:05.898945Z","shell.execute_reply":"2021-08-24T22:31:33.911724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Only Model Tuning\nuseful_features = [col for col in train_data.columns if col not in (\"id\", \"target\", \"kfold\")]\ncat_cols = [col for col in useful_features if \"cat\" in col]\nnum_cols = [col for col in useful_features if col.startswith('cont')]\ntest_data = test_data[useful_features]\n\nfinal_predictions = []\nscores = []\n\nfor fold in range(5):\n    # Preprocessing - Kfold\n    X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n    X_test = test_data.copy()\n    \n    y_train = X_train.target\n    y_valid = X_valid.target\n    \n    X_train = X_train[useful_features]\n    X_valid = X_valid[useful_features]\n    \n    # Preprocessing - Ordinal Encoding\n    ordinal_encoder = OrdinalEncoder()\n    X_train[cat_cols] = ordinal_encoder.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = ordinal_encoder.transform(X_valid[cat_cols])\n    X_test[cat_cols] = ordinal_encoder.transform(X_test[cat_cols]) # Q. The last transform\n    \n    # Training\n    #model = RandomForestRegressor(random_state=fold, n_jobs=-1)\n    #model = XGBRegressor(random_state=fold, n_jobs=8)\n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor', \n                         learning_rate=0.1, n_estimators=1000, max_depth=3, colsample_bytree=0.3)\n    model.fit(X_train, y_train)\n    \n    # Evaluation\n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    \n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:50:43.55151Z","iopub.execute_input":"2021-08-24T21:50:43.551835Z","iopub.status.idle":"2021-08-24T21:51:12.086803Z","shell.execute_reply.started":"2021-08-24T21:50:43.551803Z","shell.execute_reply":"2021-08-24T21:51:12.085859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Export submission.csv\npreds = np.mean(np.column_stack(final_predictions), axis=1)\npreds = pd.DataFrame({'id': sample_submission.id, 'target': preds})\npreds.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T21:48:43.959974Z","iopub.execute_input":"2021-08-24T21:48:43.960328Z","iopub.status.idle":"2021-08-24T21:48:44.474981Z","shell.execute_reply.started":"2021-08-24T21:48:43.960296Z","shell.execute_reply":"2021-08-24T21:48:44.474102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}